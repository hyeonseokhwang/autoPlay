#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì´ˆê³ ì† ììœ¨í•™ìŠµ ì˜ì›…ì „ì„¤4 AI - íŒ¨í„´ ì¸ì‹ ë° ìê°€ ì§„í™”
"""

import asyncio
import time
import random
import json
import sqlite3
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
import hashlib
import pickle

# ê²Œì„ ì œì–´
import cv2
import pyautogui
import win32gui
import win32con
import win32api

@dataclass
class GameState:
    """ê²Œì„ ìƒíƒœ ì •ë³´"""
    screen_hash: str
    screen_type: str
    brightness: float
    color_ratios: Dict[str, float]
    timestamp: float
    
@dataclass
class ActionResult:
    """ì•¡ì…˜ ê²°ê³¼"""
    action_name: str
    before_state: GameState
    after_state: GameState
    success: bool
    reward: float
    time_taken: float

@dataclass 
class LearnedPattern:
    """í•™ìŠµëœ íŒ¨í„´"""
    state_pattern: str
    best_action: str
    success_rate: float
    total_tries: int
    last_updated: float
    confidence: float

class HyperSpeedVision:
    """ì´ˆê³ ì† ë¹„ì „ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.hwnd_cache = None
        self.rect_cache = None
        self.last_hash = None
        
    def get_game_window(self):
        """ê²Œì„ ìœˆë„ìš° ì°¾ê¸° (ìºì‹œë¨)"""
        if self.hwnd_cache is None:
            def enum_callback(hwnd, windows):
                if win32gui.IsWindowVisible(hwnd):
                    title = win32gui.GetWindowText(hwnd)
                    if any(keyword in title for keyword in ["DOSBox", "dosbox", "ED4"]):
                        windows.append(hwnd)
                return True
                
            windows = []
            win32gui.EnumWindows(enum_callback, windows)
            self.hwnd_cache = windows[0] if windows else None
            
        return self.hwnd_cache
    
    def ultra_fast_capture(self) -> Optional[np.ndarray]:
        """ì´ˆê³ ì† í™”ë©´ ìº¡ì²˜ (0.05ì´ˆ ì´ë‚´)"""
        try:
            if self.rect_cache is None:
                hwnd = self.get_game_window()
                if not hwnd:
                    return None
                self.rect_cache = win32gui.GetWindowRect(hwnd)
            
            x, y, x2, y2 = self.rect_cache
            # ë” ì‘ì€ ì˜ì—­ë§Œ ìº¡ì²˜ (ì†ë„ í–¥ìƒ)
            w, h = x2-x, y2-y
            capture_w, capture_h = min(600, w), min(400, h)
            
            screenshot = pyautogui.screenshot(region=(x, y, capture_w, capture_h))
            return np.array(screenshot)
            
        except Exception:
            self.rect_cache = None
            return None
    
    def lightning_analyze(self, image: np.ndarray) -> GameState:
        """ë²ˆê°œ ì†ë„ ë¶„ì„ (0.02ì´ˆ ì´ë‚´)"""
        if image is None:
            return GameState("", "unknown", 0, {}, time.time())
        
        # ê·¹ë„ë¡œ ì¶•ì†Œ (16x16 í”½ì…€ë¡œ!)
        tiny = cv2.resize(image, (16, 16))
        gray_tiny = cv2.cvtColor(tiny, cv2.COLOR_RGB2GRAY)
        
        # í•´ì‹œ ìƒì„± (ìƒíƒœ ì‹ë³„ìš©)
        screen_hash = hashlib.md5(gray_tiny.tobytes()).hexdigest()[:8]
        
        # ì´ˆê³ ì† ìƒ‰ìƒ ë¶„ì„
        hsv_tiny = cv2.cvtColor(tiny, cv2.COLOR_RGB2HSV)
        
        # í‰ê· ê°’ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ì„
        brightness = float(np.mean(gray_tiny))
        
        # ìƒ‰ìƒ ë¹„ìœ¨ (4x4ë¡œ ë” ì¶•ì†Œ)
        micro = hsv_tiny[::4, ::4]  # 4x4 í”½ì…€ë§Œ ì‚¬ìš©
        
        blue_count = np.sum((micro[:,:,0] >= 100) & (micro[:,:,0] <= 130))
        red_count = np.sum((micro[:,:,0] >= 170) | (micro[:,:,0] <= 10))
        green_count = np.sum((micro[:,:,0] >= 40) & (micro[:,:,0] <= 80))
        
        total_pixels = micro.shape[0] * micro.shape[1]
        
        color_ratios = {
            'blue': blue_count / total_pixels,
            'red': red_count / total_pixels, 
            'green': green_count / total_pixels,
        }
        
        # í™”ë©´ íƒ€ì… ì¶”ë¡ 
        screen_type = 'field'
        if color_ratios['blue'] > 0.25:
            screen_type = 'menu'
        elif color_ratios['red'] > 0.2:
            screen_type = 'battle'
        elif brightness > 180:
            screen_type = 'dialogue'
        elif brightness < 50:
            screen_type = 'dark'
        
        return GameState(
            screen_hash=screen_hash,
            screen_type=screen_type,
            brightness=brightness,
            color_ratios=color_ratios,
            timestamp=time.time()
        )

class LightningController:
    """ë²ˆê°œ ì†ë„ ì»¨íŠ¸ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.hwnd_cache = None
        self.last_input_time = 0
        
    def instant_key(self, key: str) -> bool:
        """ì¦‰ì‹œ í‚¤ ì…ë ¥ (0.02ì´ˆ ì´ë‚´)"""
        current_time = time.time()
        if current_time - self.last_input_time < 0.08:  # 80ms ì œí•œ
            return False
            
        try:
            if self.hwnd_cache is None:
                def enum_callback(hwnd, windows):
                    if win32gui.IsWindowVisible(hwnd):
                        title = win32gui.GetWindowText(hwnd)
                        if any(keyword in title for keyword in ["DOSBox", "dosbox", "ED4"]):
                            windows.append(hwnd)
                    return True
                    
                windows = []
                win32gui.EnumWindows(enum_callback, windows)
                self.hwnd_cache = windows[0] if windows else None
            
            if not self.hwnd_cache:
                return False
            
            # í‚¤ ì½”ë“œ ë§¤í•‘
            key_codes = {
                'up': 0x26, 'down': 0x28, 'left': 0x25, 'right': 0x27,
                'enter': 0x0D, 'space': 0x20, 'esc': 0x1B,
                'z': 0x5A, 'x': 0x58, 'a': 0x41, 's': 0x53, 'c': 0x43
            }
            
            if key.lower() not in key_codes:
                return False
            
            vk = key_codes[key.lower()]
            
            # ì´ˆê³ ì† í‚¤ ì…ë ¥ (25msë§Œ í™€ë“œ)
            win32api.keybd_event(vk, 0, 0, 0)
            time.sleep(0.025)
            win32api.keybd_event(vk, 0, win32con.KEYEVENTF_KEYUP, 0)
            
            self.last_input_time = current_time
            return True
            
        except Exception:
            return False

class SelfLearningBrain:
    """ìê¸°í•™ìŠµ ë‡Œ"""
    
    def __init__(self):
        # ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ (SQLite)
        self.conn = sqlite3.connect(':memory:')
        self.init_memory()
        
        # ì‹¤ì‹œê°„ í•™ìŠµ ë°ì´í„°
        self.state_action_history = deque(maxlen=1000)  # ìµœê·¼ 1000ê°œ ê¸°ì–µ
        self.pattern_memory = {}  # íŒ¨í„´ -> ìµœì  ì•¡ì…˜
        self.success_memory = defaultdict(list)  # ì•¡ì…˜ë³„ ì„±ê³µ ê¸°ë¡
        self.reward_system = {}  # ë³´ìƒ ì‹œìŠ¤í…œ
        
        # í•™ìŠµ íŒŒë¼ë¯¸í„°
        self.exploration_rate = 0.3  # íƒí—˜ vs í™œìš©
        self.learning_rate = 0.1
        self.memory_decay = 0.95
        
        # ê°€ëŠ¥í•œ ì•¡ì…˜ë“¤
        self.action_space = [
            'up', 'down', 'left', 'right', 
            'enter', 'space', 'esc', 'z', 'x', 'a', 's', 'c'
        ]
        
    def init_memory(self):
        """ë©”ëª¨ë¦¬ ì´ˆê¸°í™”"""
        cursor = self.conn.cursor()
        
        # ìƒíƒœ-ì•¡ì…˜-ë³´ìƒ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE experiences (
                id INTEGER PRIMARY KEY,
                state_hash TEXT,
                action TEXT,
                reward REAL,
                next_state_hash TEXT,
                timestamp REAL
            )
        ''')
        
        # íŒ¨í„´ í•™ìŠµ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE patterns (
                state_pattern TEXT PRIMARY KEY,
                best_action TEXT,
                success_rate REAL,
                total_tries INTEGER,
                confidence REAL,
                last_updated REAL
            )
        ''')
        
        self.conn.commit()
    
    def calculate_reward(self, before_state: GameState, after_state: GameState, action: str) -> float:
        """ë³´ìƒ ê³„ì‚°"""
        reward = 0.0
        
        # í™”ë©´ ë³€í™” ë³´ìƒ (ìƒˆë¡œìš´ ìƒí™© ë°œê²¬)
        if before_state.screen_hash != after_state.screen_hash:
            reward += 2.0
        
        # í™”ë©´ íƒ€ì… ë³€í™” ë³´ìƒ
        if before_state.screen_type != after_state.screen_type:
            reward += 5.0
        
        # ë°ê¸° ë³€í™” ë³´ìƒ (ë­”ê°€ ì¼ì–´ë‚¨)
        brightness_change = abs(after_state.brightness - before_state.brightness)
        if brightness_change > 10:
            reward += brightness_change * 0.1
        
        # ìƒ‰ìƒ ë³€í™” ë³´ìƒ
        for color in ['blue', 'red', 'green']:
            color_change = abs(after_state.color_ratios.get(color, 0) - 
                              before_state.color_ratios.get(color, 0))
            if color_change > 0.1:
                reward += color_change * 3
        
        # íŠ¹ì • ìƒí™©ë³„ ë³´ìƒ
        if after_state.screen_type == 'menu' and action in ['up', 'down', 'enter']:
            reward += 1.0
        elif after_state.screen_type == 'battle' and action in ['enter', 'z', 'a']:
            reward += 1.5
        elif after_state.screen_type == 'dialogue' and action in ['enter', 'space']:
            reward += 1.0
        
        # íƒí—˜ ë³´ìƒ (ìƒˆë¡œìš´ ìƒíƒœ)
        if after_state.screen_hash not in [exp[1].screen_hash for exp in self.state_action_history]:
            reward += 3.0
        
        return reward
    
    def learn_from_experience(self, before_state: GameState, action: str, after_state: GameState):
        """ê²½í—˜ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        # ë³´ìƒ ê³„ì‚°
        reward = self.calculate_reward(before_state, after_state, action)
        
        # ê²½í—˜ ì €ì¥
        experience = (before_state, after_state, action, reward)
        self.state_action_history.append(experience)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO experiences (state_hash, action, reward, next_state_hash, timestamp)
            VALUES (?, ?, ?, ?, ?)
        ''', (before_state.screen_hash, action, reward, after_state.screen_hash, time.time()))
        
        # íŒ¨í„´ í•™ìŠµ
        self.update_patterns(before_state, action, reward)
        
        # ì„±ê³µ ê¸°ë¡ ì—…ë°ì´íŠ¸
        success = reward > 1.0
        self.success_memory[action].append(success)
        if len(self.success_memory[action]) > 50:
            self.success_memory[action].pop(0)
        
        self.conn.commit()
    
    def update_patterns(self, state: GameState, action: str, reward: float):
        """íŒ¨í„´ ì—…ë°ì´íŠ¸"""
        # ìƒíƒœ íŒ¨í„´ ìƒì„± (ë‹¨ìˆœí™”ëœ ìƒíƒœ í‘œí˜„)
        pattern = f"{state.screen_type}_{int(state.brightness/50)}_{int(state.color_ratios.get('blue', 0)*10)}"
        
        cursor = self.conn.cursor()
        cursor.execute('SELECT * FROM patterns WHERE state_pattern = ?', (pattern,))
        existing = cursor.fetchone()
        
        if existing:
            # ê¸°ì¡´ íŒ¨í„´ ì—…ë°ì´íŠ¸
            _, best_action, success_rate, total_tries, confidence, _ = existing
            
            new_total = total_tries + 1
            new_success_rate = (success_rate * total_tries + (1 if reward > 1 else 0)) / new_total
            
            # ë” ì¢‹ì€ ì•¡ì…˜ì´ë©´ ì—…ë°ì´íŠ¸
            if reward > 1 and (new_success_rate > success_rate or best_action != action):
                best_action = action
            
            new_confidence = min(0.99, confidence + 0.01)
            
            cursor.execute('''
                UPDATE patterns 
                SET best_action=?, success_rate=?, total_tries=?, confidence=?, last_updated=?
                WHERE state_pattern=?
            ''', (best_action, new_success_rate, new_total, new_confidence, time.time(), pattern))
            
        else:
            # ìƒˆ íŒ¨í„´ ì¶”ê°€
            cursor.execute('''
                INSERT INTO patterns (state_pattern, best_action, success_rate, total_tries, confidence, last_updated)
                VALUES (?, ?, ?, 1, 0.1, ?)
            ''', (pattern, action, 1 if reward > 1 else 0, time.time()))
    
    def choose_intelligent_action(self, current_state: GameState) -> str:
        """ì§€ëŠ¥ì  ì•¡ì…˜ ì„ íƒ"""
        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ìµœì  ì•¡ì…˜ ì°¾ê¸°
        pattern = f"{current_state.screen_type}_{int(current_state.brightness/50)}_{int(current_state.color_ratios.get('blue', 0)*10)}"
        
        cursor = self.conn.cursor()
        cursor.execute('SELECT best_action, confidence FROM patterns WHERE state_pattern = ?', (pattern,))
        learned_action = cursor.fetchone()
        
        # í•™ìŠµëœ íŒ¨í„´ì´ ìˆê³  ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë©´ ì‚¬ìš©
        if learned_action and learned_action[1] > 0.6:
            if random.random() > self.exploration_rate:  # í™œìš©
                return learned_action[0]
        
        # íƒí—˜ ëª¨ë“œ - ì„±ê³µë¥  ê¸°ë°˜ ì„ íƒ
        action_scores = {}
        for action in self.action_space:
            if action in self.success_memory and self.success_memory[action]:
                recent_successes = self.success_memory[action][-10:]  # ìµœê·¼ 10ê°œ
                success_rate = sum(recent_successes) / len(recent_successes)
                action_scores[action] = success_rate
            else:
                action_scores[action] = 0.5  # ê¸°ë³¸ê°’
        
        # ìƒí™©ë³„ ë³´ì •
        if current_state.screen_type == 'menu':
            for action in ['up', 'down', 'enter']:
                action_scores[action] *= 1.5
        elif current_state.screen_type == 'battle':
            for action in ['enter', 'z', 'a', 's']:
                action_scores[action] *= 1.3
        elif current_state.screen_type == 'dialogue':
            for action in ['enter', 'space']:
                action_scores[action] *= 2.0
        elif current_state.screen_type == 'field':
            for action in ['up', 'down', 'left', 'right', 'space']:
                action_scores[action] *= 1.2
        
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„ íƒ
        actions = list(action_scores.keys())
        weights = list(action_scores.values())
        
        return random.choices(actions, weights=weights)[0]
    
    def get_learning_stats(self) -> Dict:
        """í•™ìŠµ í†µê³„"""
        cursor = self.conn.cursor()
        
        # ì´ ê²½í—˜ ìˆ˜
        cursor.execute('SELECT COUNT(*) FROM experiences')
        total_experiences = cursor.fetchone()[0]
        
        # í•™ìŠµëœ íŒ¨í„´ ìˆ˜
        cursor.execute('SELECT COUNT(*) FROM patterns')
        learned_patterns = cursor.fetchone()[0]
        
        # í‰ê·  ë³´ìƒ
        cursor.execute('SELECT AVG(reward) FROM experiences')
        avg_reward = cursor.fetchone()[0] or 0
        
        # ì•¡ì…˜ë³„ ì„±ê³µë¥ 
        action_success_rates = {}
        for action in self.action_space:
            if action in self.success_memory and self.success_memory[action]:
                success_rate = sum(self.success_memory[action]) / len(self.success_memory[action])
                action_success_rates[action] = success_rate
        
        return {
            'total_experiences': total_experiences,
            'learned_patterns': learned_patterns,
            'avg_reward': avg_reward,
            'exploration_rate': self.exploration_rate,
            'best_actions': sorted(action_success_rates.items(), key=lambda x: x[1], reverse=True)[:5]
        }

class HyperIntelligentAI:
    """ì´ˆì§€ëŠ¥ AI"""
    
    def __init__(self):
        self.vision = HyperSpeedVision()
        self.controller = LightningController()
        self.brain = SelfLearningBrain()
        
        # ìƒíƒœ ì¶”ì 
        self.last_state = None
        self.action_count = 0
        self.learning_enabled = True
        
    async def hyper_fast_cycle(self) -> Dict:
        """ì´ˆê³ ì† ì‚¬ì´í´ (0.15ì´ˆ ëª©í‘œ)"""
        cycle_start = time.time()
        
        try:
            # 1. ì´ˆê³ ì† ìƒíƒœ ì¸ì‹ (0.05ì´ˆ)
            image = self.vision.ultra_fast_capture()
            current_state = self.vision.lightning_analyze(image)
            
            # 2. ì´ì „ ì•¡ì…˜ìœ¼ë¡œë¶€í„° í•™ìŠµ (0.02ì´ˆ)
            if self.last_state and self.learning_enabled:
                last_action = getattr(self, '_last_action', None)
                if last_action:
                    self.brain.learn_from_experience(self.last_state, last_action, current_state)
            
            # 3. ì§€ëŠ¥ì  ì•¡ì…˜ ì„ íƒ (0.03ì´ˆ)
            action = self.brain.choose_intelligent_action(current_state)
            
            # 4. ì¦‰ì‹œ ì‹¤í–‰ (0.03ì´ˆ)
            success = self.controller.instant_key(action)
            
            # 5. ìƒíƒœ ì—…ë°ì´íŠ¸
            self.last_state = current_state
            self._last_action = action
            self.action_count += 1
            
            cycle_time = time.time() - cycle_start
            
            return {
                'success': success,
                'action': action,
                'state': current_state.screen_type,
                'hash': current_state.screen_hash,
                'cycle_time': cycle_time,
                'learning_progress': self.action_count
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}

async def main():
    """ì´ˆê³ ì† ììœ¨í•™ìŠµ ë©”ì¸"""
    print("ğŸ§ âš¡ ì´ˆê³ ì† ììœ¨í•™ìŠµ ì˜ì›…ì „ì„¤4 AI")
    print("=" * 50)
    
    ai = HyperIntelligentAI()
    
    # ê²Œì„ ì—°ê²° í™•ì¸
    if ai.vision.ultra_fast_capture() is None:
        print("âŒ ê²Œì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    print("ğŸ® ê²Œì„ ì—°ê²° ì™„ë£Œ! ììœ¨í•™ìŠµ ì‹œì‘...")
    print("âš¡ ëª©í‘œ ì‚¬ì´í´ ì‹œê°„: 0.15ì´ˆ (6.7 cps)")
    print("ğŸ§  ì‹¤ì‹œê°„ íŒ¨í„´ í•™ìŠµ í™œì„±í™”")
    
    # ì´ˆê³ ì† í•™ìŠµ ë£¨í”„
    total_cycles = 400  # 1ë¶„ = 400ì‚¬ì´í´
    start_time = time.time()
    success_count = 0
    
    last_stats_time = start_time
    
    for cycle in range(1, total_cycles + 1):
        cycle_start_time = time.time()
        
        # ì´ˆê³ ì† ì‚¬ì´í´ ì‹¤í–‰
        result = await ai.hyper_fast_cycle()
        
        if result['success']:
            success_count += 1
        
        # 10ì‚¬ì´í´ë§ˆë‹¤ ê°„ë‹¨ ë¦¬í¬íŠ¸
        if cycle % 10 == 0:
            elapsed = time.time() - start_time
            cps = cycle / elapsed
            success_rate = success_count / cycle
            
            print(f"âš¡ #{cycle:3d} | {result.get('action', '?'):5s} | "
                  f"{result.get('state', '?'):8s} | "
                  f"ì„±ê³µ:{success_rate:.2f} | "
                  f"ì†ë„:{cps:.1f}cps | "
                  f"í•™ìŠµì§„í–‰:{result.get('learning_progress', 0)}")
        
        # 50ì‚¬ì´í´ë§ˆë‹¤ í•™ìŠµ í†µê³„
        if cycle % 50 == 0:
            stats = ai.brain.get_learning_stats()
            print(f"ğŸ“Š í•™ìŠµí†µê³„: ê²½í—˜{stats['total_experiences']} | "
                  f"íŒ¨í„´{stats['learned_patterns']} | "
                  f"í‰ê· ë³´ìƒ{stats['avg_reward']:.1f}")
            
            if stats['best_actions']:
                best_action, best_rate = stats['best_actions'][0]
                print(f"ğŸ¯ ìµœê³ ì•¡ì…˜: {best_action} ({best_rate:.2f})")
        
        # 0.15ì´ˆ ì‚¬ì´í´ ìœ ì§€ (ê°€ëŠ¥í•œ ê²½ìš°)
        cycle_elapsed = time.time() - cycle_start_time
        if cycle_elapsed < 0.15:
            await asyncio.sleep(0.15 - cycle_elapsed)
    
    # ìµœì¢… ê²°ê³¼
    total_time = time.time() - start_time
    final_stats = ai.brain.get_learning_stats()
    
    print(f"\nğŸ§  ììœ¨í•™ìŠµ ì™„ë£Œ!")
    print(f"ì´ ì‚¬ì´í´: {total_cycles}")
    print(f"ì„±ê³µë¥ : {success_count/total_cycles:.2f}")
    print(f"í‰ê· ì†ë„: {total_cycles/total_time:.1f} cps")
    print(f"í•™ìŠµëœ íŒ¨í„´: {final_stats['learned_patterns']}ê°œ")
    print(f"ì´ ê²½í—˜: {final_stats['total_experiences']}ê°œ")
    print(f"í‰ê·  ë³´ìƒ: {final_stats['avg_reward']:.2f}")
    
    print(f"\nğŸ† í•™ìŠµëœ ìµœê³  ì•¡ì…˜ë“¤:")
    for action, rate in final_stats['best_actions']:
        print(f"  {action}: {rate:.2f}")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ í•™ìŠµ ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()