"""
ğŸ® ì‹¤ì œ ê²Œì„ í”Œë ˆì´ ì¤‘ì‹¬ RAG AI
GPUë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ì„œ ì§„ì§œ ê²Œì„ì„ í”Œë ˆì´í•˜ëŠ” AI
"""

import numpy as np
import json
import time
import cv2
import pickle
from datetime import datetime
from collections import defaultdict, deque
import requests
import hashlib
import os
import sqlite3
import torch
from sentence_transformers import SentenceTransformer

class GameplayRAG:
    """ì‹¤ì œ ê²Œì„í”Œë ˆì´ ì¤‘ì‹¬ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, use_gpu=True):
        # GPU ì„¤ì •
        self.device = torch.device("cuda" if use_gpu and torch.cuda.is_available() else "cpu")
        print(f"ğŸš€ GPU ì‚¬ìš©: {self.device}")
        
        # ì„ë² ë”© ëª¨ë¸ (GPUë¡œ ë¡œë“œ)
        print("ğŸ”¤ ì„ë² ë”© ëª¨ë¸ GPU ë¡œë”© ì¤‘...")
        self.embedding_model = SentenceTransformer(
            'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
            device=self.device
        )
        print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({self.device})")
        
        # SQLite DB
        self.db_path = "gameplay_knowledge.db"
        self.init_database()
        
        # ì‹¤ì œ ê²Œì„ í–‰ë™ ë§¤í•‘
        self.actions = {
            0: {"name": "ì™¼ìª½ ì´ë™", "key": "VK_LEFT", "category": "movement"},
            1: {"name": "ì˜¤ë¥¸ìª½ ì´ë™", "key": "VK_RIGHT", "category": "movement"},
            2: {"name": "ìœ„ë¡œ ì´ë™", "key": "VK_UP", "category": "movement"},
            3: {"name": "ì•„ë˜ë¡œ ì´ë™", "key": "VK_DOWN", "category": "movement"},
            4: {"name": "í™•ì¸/ê³µê²©", "key": "VK_RETURN", "category": "action"},
            5: {"name": "ì·¨ì†Œ/ë©”ë‰´", "key": "VK_ESCAPE", "category": "action"},
            6: {"name": "ëŒ€ê¸°", "key": None, "category": "wait"}
        }
        
        print("ğŸ® ì‹¤ì œ ê²Œì„í”Œë ˆì´ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
    
    def init_database(self):
        """ê²Œì„í”Œë ˆì´ DB ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS gameplay_experiences (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                screen_before TEXT,
                action_taken INTEGER,
                screen_after TEXT,
                screen_changed BOOLEAN,
                battle_detected BOOLEAN,
                hp_changed BOOLEAN,
                success_score REAL,
                situation_description TEXT,
                learned_insight TEXT,
                embedding_vector TEXT,
                game_progress INTEGER DEFAULT 0
            )
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS successful_strategies (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                strategy_name TEXT,
                situation_context TEXT,
                action_sequence TEXT,
                success_rate REAL,
                total_uses INTEGER DEFAULT 1,
                embedding_vector TEXT,
                discovered_at TEXT
            )
        """)
        
        conn.commit()
        conn.close()
        print("ğŸ“¦ ê²Œì„í”Œë ˆì´ DB ì´ˆê¸°í™” ì™„ë£Œ")
    
    def encode_experience(self, situation_text):
        """ê²½í—˜ì„ GPUë¡œ ë²¡í„°í™”"""
        with torch.no_grad():
            # GPUì—ì„œ ë¹ ë¥´ê²Œ ì¸ì½”ë”©
            embedding = self.embedding_model.encode(
                situation_text,
                convert_to_tensor=True,
                device=self.device
            )
            return embedding.cpu().numpy().tolist()
    
    def store_gameplay_experience(self, screen_before, action, screen_after, 
                                battle_before, battle_after, success_score, situation, insight):
        """ì‹¤ì œ ê²Œì„í”Œë ˆì´ ê²½í—˜ ì €ì¥"""
        
        # ìƒí™© í…ìŠ¤íŠ¸ ìƒì„±
        situation_text = f"""
        ìƒí™©: {situation}
        í–‰ë™: {self.actions[action]['name']}
        ì „íˆ¬ìƒíƒœë³€í™”: {battle_before} â†’ {battle_after}
        ì„±ê³µë„: {success_score}
        ê¹¨ë‹¬ì€ì : {insight}
        """
        
        # GPUë¡œ ë²¡í„°í™”
        embedding = self.encode_experience(situation_text)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO gameplay_experiences 
            (timestamp, screen_before, action_taken, screen_after, 
             screen_changed, battle_detected, success_score, 
             situation_description, learned_insight, embedding_vector)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            datetime.now().isoformat(),
            screen_before,
            action,
            screen_after,
            screen_before != screen_after,
            battle_after,
            success_score,
            situation,
            insight,
            json.dumps(embedding)
        ))
        
        conn.commit()
        conn.close()
        
        return cursor.lastrowid
    
    def find_similar_situations(self, current_situation, top_k=3):
        """í˜„ì¬ ìƒí™©ê³¼ ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ ê²€ìƒ‰"""
        
        # í˜„ì¬ ìƒí™©ì„ ë²¡í„°í™”
        query_embedding = self.encode_experience(current_situation)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, action_taken, success_score, situation_description, 
                   learned_insight, embedding_vector, screen_changed, battle_detected
            FROM gameplay_experiences 
            ORDER BY id DESC LIMIT 50
        """)
        
        experiences = cursor.fetchall()
        conn.close()
        
        if not experiences:
            return []
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for exp in experiences:
            try:
                exp_embedding = json.loads(exp[5])
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                sim_score = np.dot(query_embedding, exp_embedding) / (
                    np.linalg.norm(query_embedding) * np.linalg.norm(exp_embedding)
                )
                
                similarities.append({
                    'similarity': float(sim_score),
                    'action': exp[1],
                    'success_score': exp[2],
                    'situation': exp[3],
                    'insight': exp[4],
                    'screen_changed': exp[6],
                    'battle_detected': exp[7]
                })
                
            except:
                continue
        
        # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        return similarities[:top_k]


class RealGameplayAI:
    """ì‹¤ì œ ê²Œì„ì„ í”Œë ˆì´í•˜ëŠ” AI"""
    
    def __init__(self):
        from isolated_seeker import IsolatedDOSBoxSeeker
        
        self.seeker = IsolatedDOSBoxSeeker()
        self.rag = GameplayRAG(use_gpu=True)
        
        # LLM ì„¤ì •
        self.llm_url = "http://localhost:11434/api/generate"
        self.model_name = "qwen2.5-coder:7b"
        
        # ê²Œì„ ìƒíƒœ ì¶”ì 
        self.current_hp = 100
        self.current_mp = 100
        self.battle_count = 0
        self.exploration_count = 0
        
        # í•™ìŠµ í†µê³„
        self.successful_moves = 0
        self.total_moves = 0
        
        print("ğŸ® ì‹¤ì œ ê²Œì„í”Œë ˆì´ AI ì¤€ë¹„ ì™„ë£Œ!")
        print(f"ğŸ”¥ GPU í™œìš© RAG ì‹œìŠ¤í…œ í™œì„±í™”")
    
    def analyze_game_screen(self, screen):
        """ì‹¤ì œ ê²Œì„ í™”ë©´ ë¶„ì„"""
        if screen is None:
            return {
                "type": "invalid",
                "battle_active": False,
                "characters_visible": False,
                "hp_visible": False,
                "description": "í™”ë©´ ìº¡ì²˜ ì‹¤íŒ¨"
            }
        
        # ì‹¤ì œ ê²Œì„ ìš”ì†Œ ê°ì§€
        is_battle = self.seeker.is_battle_screen(screen)
        
        # í™”ë©´ íŠ¹ì„± ë¶„ì„
        gray = cv2.cvtColor(screen, cv2.COLOR_BGR2GRAY)
        
        # í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ (HP/MP ë“±)
        text_areas = self.detect_text_regions(gray)
        
        # ìºë¦­í„°/ì  ê°ì§€
        entities = self.detect_game_entities(screen)
        
        analysis = {
            "type": "battle" if is_battle else "field",
            "battle_active": is_battle,
            "text_regions": len(text_areas),
            "entities_count": len(entities),
            "brightness": float(np.mean(gray)),
            "activity_level": float(np.std(gray)),
            "description": self.generate_scene_description(is_battle, len(text_areas), len(entities))
        }
        
        return analysis
    
    def detect_text_regions(self, gray_image):
        """í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ (HP/MP ë°” ë“±)"""
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€
        edges = cv2.Canny(gray_image, 50, 150)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        text_regions = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            # í…ìŠ¤íŠ¸ ê°™ì€ ë¹„ìœ¨ í•„í„°ë§
            if 10 < w < 200 and 5 < h < 50 and w > h:
                text_regions.append((x, y, w, h))
        
        return text_regions
    
    def detect_game_entities(self, screen):
        """ê²Œì„ ë‚´ ì—”í‹°í‹° ê°ì§€ (ìºë¦­í„°, ì  ë“±)"""
        # HSVë¡œ ë³€í™˜í•˜ì—¬ íŠ¹ì • ìƒ‰ìƒ ê°ì§€
        hsv = cv2.cvtColor(screen, cv2.COLOR_BGR2HSV)
        
        # ìºë¦­í„° ìƒ‰ìƒ ë²”ìœ„ (ëŒ€ëµì )
        lower_char = np.array([0, 50, 50])
        upper_char = np.array([180, 255, 255])
        
        mask = cv2.inRange(hsv, lower_char, upper_char)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        entities = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 100:  # ìµœì†Œ í¬ê¸° í•„í„°
                entities.append(contour)
        
        return entities
    
    def generate_scene_description(self, is_battle, text_count, entity_count):
        """ì¥ë©´ ì„¤ëª… ìƒì„±"""
        if is_battle:
            return f"ì „íˆ¬ í™”ë©´ - í…ìŠ¤íŠ¸ {text_count}ê°œ, ê°ì²´ {entity_count}ê°œ"
        else:
            return f"í•„ë“œ í™”ë©´ - í…ìŠ¤íŠ¸ {text_count}ê°œ, ê°ì²´ {entity_count}ê°œ"
    
    def make_intelligent_decision(self, screen_analysis, similar_experiences):
        """RAG ì •ë³´ ê¸°ë°˜ ì§€ëŠ¥ì  ê²°ì •"""
        
        # ìƒí™© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = f"""
í˜„ì¬ ìƒí™©:
- í™”ë©´ ìœ í˜•: {screen_analysis['type']}
- ì „íˆ¬ ìƒíƒœ: {screen_analysis['battle_active']}
- í…ìŠ¤íŠ¸ ì˜ì—­: {screen_analysis['text_regions']}ê°œ
- ê²Œì„ ê°ì²´: {screen_analysis['entities_count']}ê°œ
- í™”ë©´ í™œë™ì„±: {screen_analysis['activity_level']:.2f}

ê³¼ê±° ìœ ì‚¬í•œ ê²½í—˜:
"""
        
        for i, exp in enumerate(similar_experiences, 1):
            context += f"""
ê²½í—˜ {i} (ìœ ì‚¬ë„: {exp['similarity']:.2f}):
- í–‰ë™: {self.rag.actions[exp['action']]['name']}
- ì„±ê³µë„: {exp['success_score']:.2f}
- ê²°ê³¼: {exp['insight']}
"""
        
        # LLMì—ê²Œ ê²°ì • ìš”ì²­
        prompt = f"""
ì˜ì›…ì „ì„¤4ë¥¼ í”Œë ˆì´ ì¤‘ì…ë‹ˆë‹¤. ë‹¤ìŒ ìƒí™©ì—ì„œ ìµœì ì˜ í–‰ë™ì„ ì„ íƒí•˜ì„¸ìš”.

{context}

ì‚¬ìš© ê°€ëŠ¥í•œ í–‰ë™:
0: ì™¼ìª½ ì´ë™ (ìƒˆ ì§€ì—­ íƒí—˜)
1: ì˜¤ë¥¸ìª½ ì´ë™ (ìƒˆ ì§€ì—­ íƒí—˜)
2: ìœ„ë¡œ ì´ë™ (ìƒˆ ì§€ì—­ íƒí—˜)
3: ì•„ë˜ë¡œ ì´ë™ (ìƒˆ ì§€ì—­ íƒí—˜)
4: í™•ì¸/ê³µê²© (ì „íˆ¬ ì‹œ ê³µê²©, í‰ìƒì‹œ ì¡°ì‚¬)
5: ì·¨ì†Œ/ë©”ë‰´ (ë©”ë‰´ ì—´ê¸°, ì „íˆ¬ ì¤‘ ë°©ì–´)
6: ëŒ€ê¸° (ìƒí™© ê´€ì°°)

JSON í˜•íƒœë¡œ ë‹µí•˜ì„¸ìš”:
{{
    "action": 1,
    "reasoning": "ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™í•´ì„œ ìƒˆë¡œìš´ ì ì„ ì°¾ì•„ ì „íˆ¬ ê²½í—˜ì„ ìŒ“ê² ìŠµë‹ˆë‹¤",
    "confidence": 0.8,
    "expected_outcome": "ìƒˆë¡œìš´ ì§€ì—­ ë°œê²¬ ë˜ëŠ” ì  ì¡°ìš°"
}}
"""
        
        try:
            response = self.call_llm(prompt, timeout=10)
            decision = self.parse_json_response(response)
            
            if decision and 'action' in decision:
                return decision
            else:
                # LLM ì‹¤íŒ¨ ì‹œ RAG ê¸°ë°˜ í´ë°±
                return self.rag_based_decision(screen_analysis, similar_experiences)
                
        except Exception as e:
            print(f"âš ï¸ LLM ê²°ì • ì‹¤íŒ¨: {e}")
            return self.rag_based_decision(screen_analysis, similar_experiences)
    
    def rag_based_decision(self, screen_analysis, similar_experiences):
        """RAGë§Œìœ¼ë¡œ ê²°ì • (LLM ì‹¤íŒ¨ ì‹œ)"""
        
        # ê°€ì¥ ì„±ê³µì ì´ì—ˆë˜ ê²½í—˜ì˜ í–‰ë™ ì„ íƒ
        if similar_experiences:
            best_exp = max(similar_experiences, key=lambda x: x['success_score'])
            
            return {
                "action": best_exp['action'],
                "reasoning": f"ê³¼ê±° ì„±ê³µ ê²½í—˜ í™œìš©: {best_exp['insight']}",
                "confidence": best_exp['similarity'],
                "expected_outcome": "ê³¼ê±°ì™€ ìœ ì‚¬í•œ ê¸ì •ì  ê²°ê³¼"
            }
        
        # ê²½í—˜ì´ ì—†ìœ¼ë©´ ìƒí™©ì— ë§ëŠ” ê¸°ë³¸ í–‰ë™
        if screen_analysis['battle_active']:
            return {
                "action": 4,
                "reasoning": "ì „íˆ¬ ìƒí™©ì—ì„œ ê¸°ë³¸ ê³µê²©",
                "confidence": 0.6,
                "expected_outcome": "ì ì—ê²Œ í”¼í•´"
            }
        else:
            # íƒí—˜ í–‰ë™ (ëœë¤í•˜ê²Œ ì´ë™)
            action = np.random.choice([0, 1, 2, 3])
            return {
                "action": action,
                "reasoning": "ìƒˆë¡œìš´ ì§€ì—­ íƒí—˜",
                "confidence": 0.5,
                "expected_outcome": "ìƒˆë¡œìš´ ë°œê²¬"
            }
    
    def execute_game_action(self, action_id):
        """ì‹¤ì œ ê²Œì„ í–‰ë™ ì‹¤í–‰"""
        
        action_info = self.rag.actions[action_id]
        print(f"ğŸ® ì‹¤í–‰: {action_info['name']}")
        
        if action_info['key'] is None:
            # ëŒ€ê¸° í–‰ë™
            time.sleep(1)
            return True
        
        # ì‹¤ì œ í‚¤ ì…ë ¥
        vk_mapping = {
            "VK_LEFT": self.seeker.VK_LEFT,
            "VK_RIGHT": self.seeker.VK_RIGHT,
            "VK_UP": self.seeker.VK_UP,
            "VK_DOWN": self.seeker.VK_DOWN,
            "VK_RETURN": self.seeker.VK_RETURN,
            "VK_ESCAPE": self.seeker.VK_ESCAPE
        }
        
        vk_code = vk_mapping.get(action_info['key'])
        if vk_code:
            return self.seeker.send_key_message(vk_code)
        
        return False
    
    def evaluate_action_result(self, before_analysis, after_analysis, action, decision):
        """í–‰ë™ ê²°ê³¼ í‰ê°€"""
        
        success_score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # í™”ë©´ ë³€í™” ë³´ë„ˆìŠ¤
        if before_analysis['type'] != after_analysis['type']:
            success_score += 0.3
            print("âœ… í™”ë©´ ìƒíƒœ ë³€í™” ê°ì§€!")
        
        # ì „íˆ¬ ì§„ì… ë³´ë„ˆìŠ¤
        if not before_analysis['battle_active'] and after_analysis['battle_active']:
            success_score += 0.4
            self.battle_count += 1
            print(f"âš”ï¸ ì „íˆ¬ #{self.battle_count} ì‹œì‘!")
        
        # í™œë™ì„± ë³€í™”
        activity_change = abs(after_analysis['activity_level'] - before_analysis['activity_level'])
        if activity_change > 10:
            success_score += 0.2
            print("ğŸ“ˆ í™”ë©´ í™œë™ì„± ì¦ê°€!")
        
        # íƒí—˜ ë³´ë„ˆìŠ¤
        if self.rag.actions[action]['category'] == 'movement' and before_analysis['type'] == after_analysis['type']:
            success_score += 0.1  # ì´ë™í–ˆë‹¤ëŠ” ê²ƒ ìì²´ê°€ íƒí—˜
        
        return min(1.0, success_score)
    
    def generate_learning_insight(self, before_analysis, after_analysis, action, success_score):
        """í•™ìŠµ í†µì°° ìƒì„±"""
        
        action_name = self.rag.actions[action]['name']
        
        insights = []
        
        if success_score > 0.7:
            insights.append(f"{action_name} í–‰ë™ì´ íš¨ê³¼ì ì´ì—ˆìŒ")
        
        if before_analysis['type'] != after_analysis['type']:
            insights.append(f"í™”ë©´ ì „í™˜ ì„±ê³µ: {before_analysis['type']} â†’ {after_analysis['type']}")
        
        if after_analysis['battle_active']:
            insights.append("ì „íˆ¬ ìƒí™© ì§„ì… ì„±ê³µ")
        
        if not insights:
            insights.append(f"{action_name} ì‹¤í–‰ìœ¼ë¡œ ìƒí™© ê´€ì°°")
        
        return " | ".join(insights)
    
    def call_llm(self, prompt, timeout=10):
        """LLM í˜¸ì¶œ"""
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.3,
                "top_p": 0.8,
                "num_predict": 100
            }
        }
        
        response = requests.post(self.llm_url, json=payload, timeout=timeout)
        if response.status_code == 200:
            return response.json().get("response", "")
        else:
            raise Exception(f"LLM ì˜¤ë¥˜: {response.status_code}")
    
    def parse_json_response(self, text):
        """JSON ì‘ë‹µ íŒŒì‹±"""
        try:
            start = text.find("{")
            end = text.rfind("}") + 1
            
            if start != -1 and end > start:
                json_text = text[start:end]
                return json.loads(json_text)
            
            return None
        except:
            return None
    
    def real_gameplay_loop(self, max_actions=30):
        """ì‹¤ì œ ê²Œì„í”Œë ˆì´ ë£¨í”„"""
        
        print("ğŸš€ ì‹¤ì œ ê²Œì„í”Œë ˆì´ AI ì‹œì‘!")
        print("ğŸ® ì˜ì›…ì „ì„¤4ê°€ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!")
        print()
        
        if not self.seeker.find_dosbox_window():
            print("âŒ DOSBox ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        print("âœ… DOSBox ì—°ê²° ì„±ê³µ!")
        print(f"ğŸ¯ ëª©í‘œ: {max_actions}ë²ˆì˜ ì‹¤ì œ ê²Œì„ í–‰ë™")
        print()
        
        for action_num in range(max_actions):
            try:
                print(f"\n--- ğŸ® ê²Œì„ í–‰ë™ #{action_num + 1} ---")
                
                # 1. í˜„ì¬ í™”ë©´ ë¶„ì„
                screen_before = self.seeker.capture_dosbox_window()
                if screen_before is None:
                    print("âš ï¸ í™”ë©´ ìº¡ì²˜ ì‹¤íŒ¨")
                    continue
                
                analysis_before = self.analyze_game_screen(screen_before)
                print(f"ğŸ“Š í˜„ì¬ ìƒí™©: {analysis_before['description']}")
                
                # 2. RAGì—ì„œ ìœ ì‚¬í•œ ê²½í—˜ ê²€ìƒ‰
                situation_text = f"í™”ë©´: {analysis_before['type']}, ì „íˆ¬: {analysis_before['battle_active']}, í™œë™ì„±: {analysis_before['activity_level']:.1f}"
                similar_exp = self.rag.find_similar_situations(situation_text, top_k=3)
                
                if similar_exp:
                    print(f"ğŸ§  ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜: {len(similar_exp)}ê°œ")
                
                # 3. ì§€ëŠ¥ì  ê²°ì •
                decision = self.make_intelligent_decision(analysis_before, similar_exp)
                action = decision['action']
                
                print(f"ğŸ¯ ê²°ì •: {self.rag.actions[action]['name']}")
                print(f"ğŸ’­ ì´ìœ : {decision['reasoning']}")
                
                # 4. í–‰ë™ ì‹¤í–‰
                execution_success = self.execute_game_action(action)
                
                if not execution_success:
                    print("âŒ í–‰ë™ ì‹¤í–‰ ì‹¤íŒ¨")
                    continue
                
                # 5. ê²°ê³¼ ê´€ì°°
                time.sleep(1.5)  # ê²Œì„ ë°˜ì‘ ëŒ€ê¸°
                
                screen_after = self.seeker.capture_dosbox_window()
                if screen_after is None:
                    continue
                
                analysis_after = self.analyze_game_screen(screen_after)
                
                # 6. ê²°ê³¼ í‰ê°€ ë° í•™ìŠµ
                success_score = self.evaluate_action_result(
                    analysis_before, analysis_after, action, decision
                )
                
                insight = self.generate_learning_insight(
                    analysis_before, analysis_after, action, success_score
                )
                
                print(f"ğŸ“ˆ ì„±ê³µë„: {success_score:.2f}")
                print(f"ğŸ’¡ í•™ìŠµ: {insight}")
                
                # 7. RAGì— ê²½í—˜ ì €ì¥
                self.rag.store_gameplay_experience(
                    screen_before=str(hash(screen_before.tobytes())),
                    action=action,
                    screen_after=str(hash(screen_after.tobytes())),
                    battle_before=analysis_before['battle_active'],
                    battle_after=analysis_after['battle_active'],
                    success_score=success_score,
                    situation=situation_text,
                    insight=insight
                )
                
                # 8. í†µê³„ ì—…ë°ì´íŠ¸
                self.total_moves += 1
                if success_score > 0.6:
                    self.successful_moves += 1
                
                # 9. ì£¼ê¸°ì  ì§„í–‰ ìƒí™© ì¶œë ¥
                if (action_num + 1) % 5 == 0:
                    success_rate = self.successful_moves / self.total_moves if self.total_moves > 0 else 0
                    print(f"\nğŸ“Š ì§„í–‰ ìƒí™© ({action_num + 1}/{max_actions})")
                    print(f"   ì„±ê³µë¥ : {success_rate:.2f} ({self.successful_moves}/{self.total_moves})")
                    print(f"   ì „íˆ¬ íšŸìˆ˜: {self.battle_count}")
                
            except KeyboardInterrupt:
                print("\nâ¹ï¸ ê²Œì„í”Œë ˆì´ ì¤‘ë‹¨")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")
                continue
        
        # ìµœì¢… ê²°ê³¼
        print("\nğŸ‰ ì‹¤ì œ ê²Œì„í”Œë ˆì´ ì™„ë£Œ!")
        self.print_final_stats()
    
    def print_final_stats(self):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        success_rate = self.successful_moves / self.total_moves if self.total_moves > 0 else 0
        
        print("\n" + "="*50)
        print("ğŸ† ì‹¤ì œ ê²Œì„í”Œë ˆì´ AI ìµœì¢… ê²°ê³¼")
        print("="*50)
        print(f"ì´ í–‰ë™ ìˆ˜: {self.total_moves}")
        print(f"ì„±ê³µí•œ í–‰ë™: {self.successful_moves}")
        print(f"ì„±ê³µë¥ : {success_rate:.2%}")
        print(f"ë°œê²¬í•œ ì „íˆ¬: {self.battle_count}íšŒ")
        print(f"GPU í™œìš© ì„ë² ë”©: âœ…")
        print(f"RAG ì§€ì‹ ë² ì´ìŠ¤: {self.rag.db_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print("ğŸ® ì‹¤ì œ ê²Œì„í”Œë ˆì´ RAG AI")
    print("ğŸ”¥ GPU ê°€ì† ì„ë² ë”© + ì§„ì§œ ê²Œì„ í”Œë ˆì´")
    print()
    
    # GPU í™•ì¸
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"ğŸš€ GPU ê°ì§€: {gpu_name}")
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory // 1024**2}MB")
    else:
        print("âš ï¸ GPU ì—†ìŒ - CPUë¡œ ì‹¤í–‰")
    
    print()
    
    try:
        actions = input("ê²Œì„ í–‰ë™ íšŸìˆ˜ (ê¸°ë³¸ê°’ 20): ").strip()
        max_actions = int(actions) if actions else 20
        
        print(f"\nğŸ® {max_actions}ë²ˆì˜ ì‹¤ì œ ê²Œì„ í–‰ë™ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        print("ğŸ¯ ì˜ì›…ì „ì„¤4ê°€ DOSBoxì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”!")
        print("\nì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        input()
        
        # ì‹¤ì œ ê²Œì„í”Œë ˆì´ AI ì‹¤í–‰
        ai = RealGameplayAI()
        ai.real_gameplay_loop(max_actions=max_actions)
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì‹¤ì œ ê²Œì„í”Œë ˆì´ AI ì™„ë£Œ!")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()