"""
ğŸ§  RAG ê¸°ë°˜ ììœ¨ í•™ìŠµ ì˜ì›…ì „ì„¤4 AI
ê²½í—˜ì„ ë²¡í„°í™”í•˜ì—¬ ì§€ì†ì ìœ¼ë¡œ ì§€ì‹ì´ ì¶•ì ë˜ëŠ” ì‹œìŠ¤í…œ
"""

import numpy as np
import json
import time
import cv2
import pickle
from datetime import datetime
from collections import defaultdict, deque
import requests
import hashlib
import os
import sqlite3
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import torch

class GameKnowledgeRAG:
    """ê²Œì„ ì§€ì‹ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, db_path="game_knowledge.db"):
        self.db_path = db_path
        self.embedding_model = None
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        
        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self.init_vector_database()
        self.load_embedding_model()
        
        # ì§€ì‹ ì¹´í…Œê³ ë¦¬
        self.knowledge_categories = {
            "screen_states": "í™”ë©´ ìƒíƒœë³„ ìµœì  í–‰ë™",
            "battle_patterns": "ì „íˆ¬ íŒ¨í„´ ë° ì „ëµ", 
            "exploration_routes": "íƒí—˜ ê²½ë¡œ ë° ë°œê²¬",
            "success_sequences": "ì„±ê³µì ì¸ í–‰ë™ ì‹œí€€ìŠ¤",
            "failure_analysis": "ì‹¤íŒ¨ ì›ì¸ ë° êµí›ˆ",
            "game_mechanics": "ê²Œì„ ë©”ì»¤ë‹ˆì¦˜ ì´í•´",
            "contextual_hints": "ìƒí™©ë³„ íŒíŠ¸ ë° íŒ"
        }
    
    def init_vector_database(self):
        """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        self.conn = sqlite3.connect(self.db_path)
        cursor = self.conn.cursor()
        
        # ê²½í—˜ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS experiences (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                category TEXT,
                screen_hash TEXT,
                action_taken TEXT,
                result TEXT,
                success_score REAL,
                context_description TEXT,
                learned_concept TEXT,
                embedding_vector TEXT,
                relevance_count INTEGER DEFAULT 0
            )
        """)
        
        # íŒ¨í„´ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                pattern_name TEXT UNIQUE,
                pattern_description TEXT,
                confidence_score REAL,
                usage_count INTEGER DEFAULT 0,
                last_updated TEXT,
                embedding_vector TEXT
            )
        """)
        
        # ì„±ê³µ ì‹œí€€ìŠ¤ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS success_sequences (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                sequence_name TEXT,
                actions_sequence TEXT,
                context_conditions TEXT,
                success_rate REAL,
                total_attempts INTEGER,
                embedding_vector TEXT
            )
        """)
        
        self.conn.commit()
        print("ğŸ“¦ RAG ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_embedding_model(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
        try:
            # í•œêµ­ì–´ ì§€ì› ì„ë² ë”© ëª¨ë¸
            self.embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
            print("ğŸ”¤ ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ëŒ€ì•ˆ: TF-IDF ë²¡í„°ë¼ì´ì € ì‚¬ìš©")
            self.embedding_model = None
    
    def vectorize_experience(self, experience_text):
        """ê²½í—˜ì„ ë²¡í„°ë¡œ ë³€í™˜"""
        if self.embedding_model:
            # Sentence Transformers ì‚¬ìš©
            embedding = self.embedding_model.encode(experience_text)
            return embedding.tolist()
        else:
            # TF-IDF ëŒ€ì•ˆ ì‚¬ìš©
            try:
                tfidf_matrix = self.vectorizer.fit_transform([experience_text])
                return tfidf_matrix.toarray()[0].tolist()
            except:
                return [0.0] * 100  # ê¸°ë³¸ ë²¡í„°
    
    def store_experience(self, category, screen_hash, action, result, success_score, context, learned_concept):
        """ê²½í—˜ì„ RAG ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        
        # ê²½í—˜ì„ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        experience_text = f"""
        ìƒí™©: {context}
        í™”ë©´: {screen_hash}
        í–‰ë™: {action}
        ê²°ê³¼: {result}
        ì„±ê³µë„: {success_score}
        í•™ìŠµë‚´ìš©: {learned_concept}
        """
        
        # ë²¡í„°í™”
        embedding_vector = self.vectorize_experience(experience_text)
        embedding_json = json.dumps(embedding_vector)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT INTO experiences 
            (timestamp, category, screen_hash, action_taken, result, 
             success_score, context_description, learned_concept, embedding_vector)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            datetime.now().isoformat(),
            category,
            screen_hash, 
            str(action),
            result,
            success_score,
            context,
            learned_concept,
            embedding_json
        ))
        
        self.conn.commit()
        experience_id = cursor.lastrowid
        
        print(f"ğŸ’¾ ê²½í—˜ ì €ì¥ë¨ (ID: {experience_id}): {learned_concept}")
        return experience_id
    
    def retrieve_relevant_experiences(self, current_context, top_k=5):
        """í˜„ì¬ ìƒí™©ê³¼ ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ ê²€ìƒ‰"""
        
        # í˜„ì¬ ìƒí™©ì„ ë²¡í„°í™”
        query_vector = self.vectorize_experience(current_context)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ê²½í—˜ ê°€ì ¸ì˜¤ê¸°
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM experiences ORDER BY timestamp DESC LIMIT 100")
        experiences = cursor.fetchall()
        
        if not experiences:
            return []
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for exp in experiences:
            exp_id = exp[0]
            embedding_json = exp[9]  # embedding_vector ì»¬ëŸ¼
            
            try:
                exp_vector = json.loads(embedding_json)
                
                # ë²¡í„° ê¸¸ì´ ë§ì¶”ê¸°
                if len(exp_vector) != len(query_vector):
                    continue
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = cosine_similarity([query_vector], [exp_vector])[0][0]
                similarities.append((similarity, exp))
                
            except Exception as e:
                continue
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        similarities.sort(key=lambda x: x[0], reverse=True)
        
        # ìƒìœ„ kê°œ ë°˜í™˜
        relevant_experiences = []
        for sim_score, exp in similarities[:top_k]:
            relevant_experiences.append({
                'id': exp[0],
                'similarity': sim_score,
                'category': exp[2],
                'action': exp[4],
                'result': exp[5],
                'success_score': exp[6],
                'context': exp[7],
                'learned_concept': exp[8],
                'timestamp': exp[1]
            })
        
        return relevant_experiences
    
    def extract_pattern(self, experiences_batch):
        """ê²½í—˜ ë°°ì¹˜ì—ì„œ íŒ¨í„´ ì¶”ì¶œ"""
        if len(experiences_batch) < 3:
            return None
        
        # ì„±ê³µì ì¸ ê²½í—˜ë“¤ ë¶„ì„
        successful_experiences = [exp for exp in experiences_batch if exp['success_score'] > 0.6]
        
        if len(successful_experiences) < 2:
            return None
        
        # ê³µí†µ íŒ¨í„´ ì°¾ê¸°
        common_actions = defaultdict(int)
        common_contexts = defaultdict(int)
        
        for exp in successful_experiences:
            common_actions[exp['action']] += 1
            # ì»¨í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            context_words = exp['context'].split()
            for word in context_words:
                if len(word) > 2:  # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ
                    common_contexts[word] += 1
        
        # íŒ¨í„´ ìƒì„±
        if common_actions and common_contexts:
            most_common_action = max(common_actions.items(), key=lambda x: x[1])
            most_common_context = max(common_contexts.items(), key=lambda x: x[1])
            
            pattern_name = f"{most_common_context[0]}_{most_common_action[0]}"
            pattern_description = f"{most_common_context[0]} ìƒí™©ì—ì„œ {most_common_action[0]} í–‰ë™ì´ íš¨ê³¼ì "
            
            confidence_score = (most_common_action[1] + most_common_context[1]) / len(successful_experiences)
            
            # íŒ¨í„´ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            self.store_pattern(pattern_name, pattern_description, confidence_score)
            
            return {
                'name': pattern_name,
                'description': pattern_description,
                'confidence': confidence_score
            }
        
        return None
    
    def store_pattern(self, pattern_name, description, confidence):
        """íŒ¨í„´ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        
        # íŒ¨í„´ ì„¤ëª…ì„ ë²¡í„°í™”
        pattern_vector = self.vectorize_experience(description)
        embedding_json = json.dumps(pattern_vector)
        
        cursor = self.conn.cursor()
        
        # ê¸°ì¡´ íŒ¨í„´ ì—…ë°ì´íŠ¸ ë˜ëŠ” ìƒˆë¡œ ì‚½ì…
        cursor.execute("""
            INSERT OR REPLACE INTO patterns 
            (pattern_name, pattern_description, confidence_score, usage_count, last_updated, embedding_vector)
            VALUES (?, ?, ?, 
                    COALESCE((SELECT usage_count FROM patterns WHERE pattern_name = ?) + 1, 1),
                    ?, ?)
        """, (pattern_name, description, confidence, pattern_name, 
              datetime.now().isoformat(), embedding_json))
        
        self.conn.commit()
        print(f"ğŸ§© íŒ¨í„´ ì €ì¥: {pattern_name} (ì‹ ë¢°ë„: {confidence:.2f})")
    
    def get_contextual_advice(self, current_situation):
        """í˜„ì¬ ìƒí™©ì— ë§ëŠ” ì¡°ì–¸ ìƒì„±"""
        
        # ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ ê²€ìƒ‰
        relevant_experiences = self.retrieve_relevant_experiences(current_situation, top_k=3)
        
        if not relevant_experiences:
            return "ì´ì „ ê²½í—˜ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. íƒí—˜ì„ í†µí•´ í•™ìŠµí•˜ê² ìŠµë‹ˆë‹¤."
        
        # ì¡°ì–¸ ìƒì„±
        advice_parts = []
        
        for exp in relevant_experiences:
            if exp['similarity'] > 0.7:  # ë†’ì€ ìœ ì‚¬ë„ë§Œ
                success_indicator = "ì„±ê³µì " if exp['success_score'] > 0.6 else "ì‹¤íŒ¨í•œ"
                advice_parts.append(
                    f"ìœ ì‚¬í•œ ìƒí™©ì—ì„œ '{exp['action']}' í–‰ë™ì´ {success_indicator}ì´ì—ˆìŠµë‹ˆë‹¤ "
                    f"(ìœ ì‚¬ë„: {exp['similarity']:.2f})"
                )
        
        if advice_parts:
            return " | ".join(advice_parts)
        else:
            return "ìœ ì‚¬í•œ ê²½í—˜ì´ ìˆì§€ë§Œ í™•ì‹¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹ ì¤‘íˆ íƒí—˜í•˜ê² ìŠµë‹ˆë‹¤."
    
    def get_knowledge_summary(self):
        """ì¶•ì ëœ ì§€ì‹ ìš”ì•½"""
        cursor = self.conn.cursor()
        
        # í†µê³„ ìˆ˜ì§‘
        cursor.execute("SELECT COUNT(*) FROM experiences")
        total_experiences = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM patterns") 
        total_patterns = cursor.fetchone()[0]
        
        cursor.execute("SELECT category, COUNT(*) FROM experiences GROUP BY category")
        category_stats = cursor.fetchall()
        
        cursor.execute("SELECT AVG(success_score) FROM experiences")
        avg_success = cursor.fetchone()[0] or 0
        
        summary = {
            'total_experiences': total_experiences,
            'total_patterns': total_patterns,
            'avg_success_rate': avg_success,
            'category_distribution': dict(category_stats)
        }
        
        return summary


class RAGEnhancedSelfLearningAI:
    """RAG ê°•í™” ììœ¨ í•™ìŠµ AI"""
    
    def __init__(self):
        from isolated_seeker import IsolatedDOSBoxSeeker
        
        self.base_seeker = IsolatedDOSBoxSeeker()
        
        # LLM ì„¤ì •
        self.llm_endpoint = "http://localhost:11434/api/generate"
        self.model = "qwen2.5-coder:7b"
        
        # RAG ì‹œìŠ¤í…œ
        self.rag_system = GameKnowledgeRAG()
        
        # í•™ìŠµ ì„¸ì…˜ ê´€ë¦¬
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.exploration_count = 0
        self.learning_batch_size = 5
        self.pending_experiences = []
        
        print("ğŸ§  RAG ê°•í™” ììœ¨ í•™ìŠµ AI ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“Š ì„¸ì…˜ ID: {self.session_id}")
        
        # ê¸°ì¡´ ì§€ì‹ ìš”ì•½ ì¶œë ¥
        self.print_knowledge_status()
    
    def print_knowledge_status(self):
        """í˜„ì¬ ì§€ì‹ ìƒíƒœ ì¶œë ¥"""
        summary = self.rag_system.get_knowledge_summary()
        
        print(f"\nğŸ“š í˜„ì¬ ì§€ì‹ ìƒíƒœ:")
        print(f"   ì´ ê²½í—˜: {summary['total_experiences']}ê°œ")
        print(f"   ë°œê²¬í•œ íŒ¨í„´: {summary['total_patterns']}ê°œ")
        print(f"   í‰ê·  ì„±ê³µë¥ : {summary['avg_success_rate']:.2f}")
        
        if summary['category_distribution']:
            print(f"   ì¹´í…Œê³ ë¦¬ë³„ ê²½í—˜:")
            for category, count in summary['category_distribution'].items():
                print(f"     - {category}: {count}ê°œ")
    
    def analyze_screen_with_rag(self, screen):
        """RAGë¥¼ í™œìš©í•œ í™”ë©´ ë¶„ì„"""
        
        # ê¸°ë³¸ í™”ë©´ ë¶„ì„
        screen_hash = self.hash_screen(screen)
        basic_analysis = self.analyze_screen_basic(screen)
        
        # RAGì—ì„œ ê´€ë ¨ ê²½í—˜ ê²€ìƒ‰
        current_context = f"í™”ë©´ìœ í˜•: {basic_analysis.get('screen_type', 'ì•Œìˆ˜ì—†ìŒ')}, íŠ¹ì§•: {basic_analysis.get('prominent_elements', [])}"
        
        relevant_experiences = self.rag_system.retrieve_relevant_experiences(current_context, top_k=3)
        
        # ìƒí™©ë³„ ì¡°ì–¸ ê°€ì ¸ì˜¤ê¸°
        contextual_advice = self.rag_system.get_contextual_advice(current_context)
        
        # LLMì—ê²Œ RAG ì •ë³´ì™€ í•¨ê»˜ ë¶„ì„ ìš”ì²­
        rag_enhanced_prompt = f"""
ë‹¹ì‹ ì€ ì´ ê²Œì„ì„ í•™ìŠµ ì¤‘ì¸ AIì…ë‹ˆë‹¤.

í˜„ì¬ í™”ë©´ ë¶„ì„:
{json.dumps(basic_analysis, ensure_ascii=False, indent=2)}

ê³¼ê±° ìœ ì‚¬í•œ ê²½í—˜ë“¤:
{self.format_experiences_for_llm(relevant_experiences)}

AI ì¡°ì–¸:
{contextual_advice}

ì´ ì •ë³´ë“¤ì„ ì¢…í•©í•˜ì—¬ ë‹¤ìŒì„ ê²°ì •í•´ì£¼ì„¸ìš”:

1. í˜„ì¬ ìƒí™©ì— ëŒ€í•œ ì´í•´
2. ì¶”ì²œí•˜ëŠ” í–‰ë™ (0-6)
3. ê·¸ ì´ìœ 
4. ì˜ˆìƒë˜ëŠ” ê²°ê³¼
5. ì´ë²ˆ í–‰ë™ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ê²ƒ

JSON í˜•íƒœë¡œ:
{{
    "situation_understanding": "ìƒí™© ì´í•´",
    "recommended_action": 2,
    "reasoning": "ì„ íƒ ì´ìœ ",
    "expected_outcome": "ì˜ˆìƒ ê²°ê³¼",
    "learning_opportunity": "í•™ìŠµ ê¸°íšŒ"
}}
"""
        
        try:
            llm_response = self.call_llm(rag_enhanced_prompt)
            decision = self.parse_llm_json(llm_response)
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            if not decision or 'recommended_action' not in decision:
                decision = {
                    "situation_understanding": basic_analysis.get('screen_type', 'ì•Œìˆ˜ì—†ìŒ'),
                    "recommended_action": np.random.randint(0, 7),
                    "reasoning": "RAG ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ íƒí—˜ì  í–‰ë™",
                    "expected_outcome": "ìƒˆë¡œìš´ ì •ë³´ ë°œê²¬ ê¸°ëŒ€",
                    "learning_opportunity": "ì´ ìƒí™©ì—ì„œì˜ í–‰ë™ ê²°ê³¼ í•™ìŠµ"
                }
            
            return decision, current_context, relevant_experiences
            
        except Exception as e:
            print(f"âš ï¸ RAG ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self.fallback_decision(), current_context, []
    
    def format_experiences_for_llm(self, experiences):
        """ê²½í—˜ë“¤ì„ LLMì´ ì´í•´í•˜ê¸° ì‰½ê²Œ í¬ë§·íŒ…"""
        if not experiences:
            return "ê´€ë ¨ëœ ê³¼ê±° ê²½í—˜ì´ ì—†ìŠµë‹ˆë‹¤."
        
        formatted = []
        for i, exp in enumerate(experiences, 1):
            success_desc = "ì„±ê³µì " if exp['success_score'] > 0.6 else "ì‹¤íŒ¨í•œ"
            formatted.append(f"""
ê²½í—˜ {i} (ìœ ì‚¬ë„: {exp['similarity']:.2f}):
- í–‰ë™: {exp['action']}
- ê²°ê³¼: {exp['result']} ({success_desc})
- í•™ìŠµë‚´ìš©: {exp['learned_concept']}
""")
        
        return "\n".join(formatted)
    
    def learn_and_store_experience(self, before_context, action_decision, after_screen, after_context):
        """ê²½í—˜ì„ ë¶„ì„í•˜ê³  RAGì— ì €ì¥"""
        
        # ì„±ê³µë„ í‰ê°€
        success_score = self.evaluate_action_success(before_context, action_decision, after_context)
        
        # í•™ìŠµëœ ê°œë… ì¶”ì¶œ
        learning_prompt = f"""
ë‹¤ìŒ í–‰ë™ì˜ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ê°œë…ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

ì´ì „ ìƒí™©: {before_context}
ì„ íƒí•œ í–‰ë™: {action_decision.get('recommended_action')} - {action_decision.get('reasoning')}
ì˜ˆìƒ ê²°ê³¼: {action_decision.get('expected_outcome')}
ì‹¤ì œ ê²°ê³¼: {after_context}
ì„±ê³µë„: {success_score}

í•™ìŠµí•  ìˆ˜ ìˆëŠ” ê°œë…ì´ë‚˜ ê·œì¹™ì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
        
        try:
            learning_response = self.call_llm(learning_prompt)
            learned_concept = learning_response.strip()
        except:
            learned_concept = f"í–‰ë™ {action_decision.get('recommended_action')} ê²°ê³¼ ê´€ì°°"
        
        # ì¹´í…Œê³ ë¦¬ ê²°ì •
        category = self.determine_experience_category(before_context, action_decision)
        
        # RAGì— ì €ì¥
        screen_hash = self.hash_screen(after_screen) if after_screen is not None else "unknown"
        
        experience_id = self.rag_system.store_experience(
            category=category,
            screen_hash=screen_hash,
            action=action_decision.get('recommended_action'),
            result=after_context,
            success_score=success_score,
            context=before_context,
            learned_concept=learned_concept
        )
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ ëŒ€ê¸°ì—´ì— ì¶”ê°€
        self.pending_experiences.append({
            'id': experience_id,
            'category': category,
            'action': action_decision.get('recommended_action'),
            'result': after_context,
            'success_score': success_score,
            'context': before_context,
            'learned_concept': learned_concept,
            'timestamp': datetime.now().isoformat()
        })
        
        # ë°°ì¹˜ê°€ ì°¼ìœ¼ë©´ íŒ¨í„´ ì¶”ì¶œ
        if len(self.pending_experiences) >= self.learning_batch_size:
            self.process_learning_batch()
        
        return learned_concept
    
    def process_learning_batch(self):
        """í•™ìŠµ ë°°ì¹˜ ì²˜ë¦¬ ë° íŒ¨í„´ ì¶”ì¶œ"""
        print(f"\nğŸ” {len(self.pending_experiences)}ê°œ ê²½í—˜ìœ¼ë¡œë¶€í„° íŒ¨í„´ ì¶”ì¶œ ì¤‘...")
        
        # íŒ¨í„´ ì¶”ì¶œ
        extracted_pattern = self.rag_system.extract_pattern(self.pending_experiences)
        
        if extracted_pattern:
            print(f"ğŸ’¡ ìƒˆë¡œìš´ íŒ¨í„´ ë°œê²¬: {extracted_pattern['name']}")
            print(f"   ì„¤ëª…: {extracted_pattern['description']}")
            print(f"   ì‹ ë¢°ë„: {extracted_pattern['confidence']:.2f}")
        
        # ë°°ì¹˜ ì´ˆê¸°í™”
        self.pending_experiences = []
        
        # ì£¼ê¸°ì  ì§€ì‹ ìš”ì•½ ì¶œë ¥
        if self.exploration_count % 20 == 0:
            self.print_knowledge_status()
    
    def evaluate_action_success(self, before_context, action_decision, after_context):
        """í–‰ë™ì˜ ì„±ê³µë„ í‰ê°€"""
        
        # ê¸°ë³¸ ì„±ê³µë„ (í™”ë©´ ë³€í™” ìˆìœ¼ë©´ 0.5)
        base_score = 0.5 if "í™”ë©´" in after_context else 0.3
        
        # ì˜ˆìƒê³¼ ì‹¤ì œ ê²°ê³¼ ë¹„êµ
        expected = action_decision.get('expected_outcome', '').lower()
        actual = after_context.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì˜ˆìƒ ì •í™•ë„ ì¸¡ì •
        expected_words = set(expected.split())
        actual_words = set(actual.split())
        
        if expected_words and actual_words:
            overlap = len(expected_words.intersection(actual_words))
            prediction_accuracy = overlap / len(expected_words.union(actual_words))
            base_score += prediction_accuracy * 0.3
        
        # íƒí—˜ ë³´ë„ˆìŠ¤ (ìƒˆë¡œìš´ ê²ƒ ë°œê²¬)
        if "ìƒˆë¡œìš´" in after_context or "ë°œê²¬" in after_context:
            base_score += 0.2
        
        return min(1.0, base_score)
    
    def determine_experience_category(self, context, action_decision):
        """ê²½í—˜ì˜ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        
        context_lower = context.lower()
        reasoning_lower = action_decision.get('reasoning', '').lower()
        
        if any(word in context_lower for word in ['ì „íˆ¬', 'battle', 'hp', 'mp']):
            return 'battle_patterns'
        elif any(word in reasoning_lower for word in ['íƒí—˜', 'ì´ë™', 'ìƒˆë¡œìš´']):
            return 'exploration_routes'
        elif 'ì„±ê³µ' in reasoning_lower or 'íš¨ê³¼' in reasoning_lower:
            return 'success_sequences'
        elif 'ì‹¤íŒ¨' in reasoning_lower or 'ì˜ëª»' in reasoning_lower:
            return 'failure_analysis'
        elif any(word in context_lower for word in ['í™”ë©´', 'ë©”ë‰´', 'ìƒíƒœ']):
            return 'screen_states'
        else:
            return 'game_mechanics'
    
    def hash_screen(self, screen):
        """í™”ë©´ í•´ì‹œ ìƒì„±"""
        if screen is None:
            return "no_screen"
        
        small_screen = cv2.resize(screen, (64, 48))
        gray = cv2.cvtColor(small_screen, cv2.COLOR_BGR2GRAY)
        
        features = [
            np.mean(gray),
            np.std(gray), 
            len(np.unique(gray)),
            cv2.Laplacian(gray, cv2.CV_64F).var()
        ]
        
        feature_str = "_".join(f"{f:.2f}" for f in features)
        return hashlib.md5(feature_str.encode()).hexdigest()[:8]
    
    def analyze_screen_basic(self, screen):
        """ê¸°ë³¸ í™”ë©´ ë¶„ì„"""
        if screen is None:
            return {"screen_type": "invalid", "prominent_elements": []}
        
        # ê°„ë‹¨í•œ ì‹œê°ì  íŠ¹ì§• ì¶”ì¶œ
        gray = cv2.cvtColor(screen, cv2.COLOR_BGR2GRAY)
        
        return {
            "screen_type": "game_screen",
            "prominent_elements": ["UIìš”ì†Œ", "ê²Œì„í™”ë©´"],
            "brightness": float(np.mean(gray)),
            "contrast": float(np.std(gray))
        }
    
    def call_llm(self, prompt, timeout=15):
        """LLM í˜¸ì¶œ"""
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9
            }
        }
        
        response = requests.post(self.llm_endpoint, json=payload, timeout=timeout)
        if response.status_code == 200:
            return response.json().get("response", "")
        else:
            raise Exception(f"LLM API ì˜¤ë¥˜: {response.status_code}")
    
    def parse_llm_json(self, text):
        """LLM ì‘ë‹µ JSON íŒŒì‹±"""
        try:
            start = text.find("{")
            end = text.rfind("}") + 1
            
            if start != -1 and end > start:
                json_text = text[start:end]
                return json.loads(json_text)
            return {}
        except:
            return {}
    
    def fallback_decision(self):
        """í´ë°± ê²°ì •"""
        return {
            "situation_understanding": "ë¶„ì„ ì‹¤íŒ¨",
            "recommended_action": np.random.randint(0, 7),
            "reasoning": "ëœë¤ íƒí—˜",
            "expected_outcome": "ìƒˆë¡œìš´ ì •ë³´",
            "learning_opportunity": "ê¸°ë³¸ í–‰ë™ ë°˜ì‘ í•™ìŠµ"
        }
    
    def execute_action(self, action_id):
        """í–‰ë™ ì‹¤í–‰"""
        vk_keys = {
            0: self.base_seeker.VK_LEFT,
            1: self.base_seeker.VK_RIGHT,
            2: self.base_seeker.VK_UP,
            3: self.base_seeker.VK_DOWN,
            4: self.base_seeker.VK_RETURN,
            5: self.base_seeker.VK_ESCAPE,
            6: None
        }
        
        vk_code = vk_keys.get(action_id)
        if vk_code is not None:
            return self.base_seeker.send_key_message(vk_code)
        return True
    
    def autonomous_rag_learning(self, max_iterations=100):
        """RAG ê¸°ë°˜ ììœ¨ í•™ìŠµ ì‹¤í–‰"""
        
        print("ğŸš€ RAG ê¸°ë°˜ ììœ¨ í•™ìŠµ ì‹œì‘!")
        print("ğŸ“Š ê²½í—˜ì´ ì¶•ì ë ìˆ˜ë¡ ë” ë˜‘ë˜‘í•´ì§‘ë‹ˆë‹¤")
        print()
        
        if not self.base_seeker.find_dosbox_window():
            print("âŒ DOSBox ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        while self.exploration_count < max_iterations:
            try:
                print(f"\n--- RAG í•™ìŠµ #{self.exploration_count + 1} ---")
                
                # í˜„ì¬ í™”ë©´ ìº¡ì²˜
                current_screen = self.base_seeker.capture_dosbox_window()
                if current_screen is None:
                    continue
                
                # RAG ê°•í™” ë¶„ì„
                decision, context_before, relevant_exp = self.analyze_screen_with_rag(current_screen)
                
                print(f"ğŸ§  ìƒí™© ì´í•´: {decision['situation_understanding']}")
                print(f"ğŸ¯ ì„ íƒí•œ í–‰ë™: {decision['recommended_action']} - {decision['reasoning']}")
                
                if relevant_exp:
                    print(f"ğŸ“š í™œìš©ëœ ê³¼ê±° ê²½í—˜: {len(relevant_exp)}ê°œ")
                
                # í–‰ë™ ì‹¤í–‰
                self.execute_action(decision['recommended_action'])
                
                # ê²°ê³¼ ê´€ì°°
                time.sleep(1.5)
                result_screen = self.base_seeker.capture_dosbox_window()
                
                if result_screen is not None:
                    # ê²°ê³¼ ë¶„ì„
                    context_after = f"í–‰ë™ í›„ í™”ë©´ ë³€í™” ê´€ì°°ë¨"
                    
                    # ê²½í—˜ ì €ì¥ ë° í•™ìŠµ
                    learned_concept = self.learn_and_store_experience(
                        context_before, decision, result_screen, context_after
                    )
                    
                    print(f"ğŸ’¡ í•™ìŠµ: {learned_concept}")
                
                self.exploration_count += 1
                
                # ì£¼ê¸°ì  ì§„í–‰ ìƒí™© ì¶œë ¥
                if self.exploration_count % 10 == 0:
                    summary = self.rag_system.get_knowledge_summary()
                    print(f"\nğŸ“ˆ ì§„í–‰ ìƒí™© ({self.exploration_count}íšŒ íƒí—˜)")
                    print(f"   ì¶•ì ëœ ê²½í—˜: {summary['total_experiences']}ê°œ")
                    print(f"   ë°œê²¬í•œ íŒ¨í„´: {summary['total_patterns']}ê°œ")
                    print(f"   í˜„ì¬ ì„±ê³µë¥ : {summary['avg_success_rate']:.2f}")
                
            except KeyboardInterrupt:
                print("\nâ¹ï¸ í•™ìŠµ ì¤‘ë‹¨")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")
                self.exploration_count += 1
        
        # ìµœì¢… ì²˜ë¦¬
        if self.pending_experiences:
            self.process_learning_batch()
        
        print("\nğŸ‰ RAG ê¸°ë°˜ ììœ¨ í•™ìŠµ ì™„ë£Œ!")
        self.print_final_rag_report()
    
    def print_final_rag_report(self):
        """ìµœì¢… RAG í•™ìŠµ ë³´ê³ ì„œ"""
        summary = self.rag_system.get_knowledge_summary()
        
        print("\n" + "="*60)
        print("ğŸ§  RAG ê¸°ë°˜ ììœ¨ í•™ìŠµ ìµœì¢… ë³´ê³ ì„œ")
        print("="*60)
        
        print(f"ğŸ“Š í•™ìŠµ í†µê³„:")
        print(f"   ì´ íƒí—˜ íšŸìˆ˜: {self.exploration_count}")
        print(f"   ì¶•ì ëœ ê²½í—˜: {summary['total_experiences']}ê°œ")
        print(f"   ë°œê²¬í•œ íŒ¨í„´: {summary['total_patterns']}ê°œ") 
        print(f"   ìµœì¢… ì„±ê³µë¥ : {summary['avg_success_rate']:.2f}")
        
        print(f"\nğŸ“š ì¹´í…Œê³ ë¦¬ë³„ í•™ìŠµ í˜„í™©:")
        for category, count in summary['category_distribution'].items():
            print(f"   {category}: {count}ê°œ ê²½í—˜")
        
        print(f"\nğŸ¯ RAG ì‹œìŠ¤í…œ íš¨ê³¼:")
        print(f"   - ê²½í—˜ ë²¡í„°í™”ë¡œ ìœ ì‚¬ ìƒí™© ë¹ ë¥¸ ê²€ìƒ‰")
        print(f"   - íŒ¨í„´ ìë™ ì¶”ì¶œë¡œ ì „ëµ ê°œë°œ")
        print(f"   - ì§€ì†ì  ì§€ì‹ ì¶•ì ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ")
        
        print(f"\nğŸ’¾ ì§€ì‹ë² ì´ìŠ¤: {self.rag_system.db_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ§  RAG ê¸°ë°˜ ììœ¨ í•™ìŠµ ì˜ì›…ì „ì„¤4 AI")
    print("ğŸ“š ê²½í—˜ì„ ë²¡í„°í™”í•˜ì—¬ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ì‹œìŠ¤í…œ")
    print()
    
    print("ğŸš€ íŠ¹ì§•:")
    print("- ëª¨ë“  ê²½í—˜ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥")
    print("- ìœ ì‚¬í•œ ìƒí™©ì—ì„œ ê³¼ê±° ê²½í—˜ í™œìš©")
    print("- ìë™ íŒ¨í„´ ì¶”ì¶œ ë° ì „ëµ ê°œë°œ")
    print("- ì„¸ì…˜ ê°„ ì§€ì‹ ëˆ„ì  (ì˜êµ¬ í•™ìŠµ)")
    print()
    
    try:
        # ì˜ì¡´ì„± í™•ì¸
        try:
            import sentence_transformers
            print("âœ… Sentence Transformers ì‚¬ìš© ê°€ëŠ¥")
        except ImportError:
            print("âš ï¸ Sentence Transformers ì—†ìŒ. pip install sentence-transformers")
            print("   TF-IDF ë°±ì—… ì‹œìŠ¤í…œ ì‚¬ìš©")
        
        iterations = input("í•™ìŠµ íšŸìˆ˜ (ê¸°ë³¸ê°’ 50): ").strip()
        max_iterations = int(iterations) if iterations else 50
        
        print(f"\nğŸš€ {max_iterations}íšŒ RAG ê¸°ë°˜ ììœ¨ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        print("ğŸ’¡ Ctrl+Cë¡œ ì¤‘ë‹¨ ì‹œ í•™ìŠµí•œ ë‚´ìš©ì€ ìë™ ì €ì¥ë©ë‹ˆë‹¤")
        print("\nì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        input()
        
        # RAG ê°•í™” AI ì‹¤í–‰
        ai = RAGEnhancedSelfLearningAI()
        ai.autonomous_rag_learning(max_iterations=max_iterations)
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ RAG í•™ìŠµ ì‹œìŠ¤í…œ ê°œë°œ ì™„ë£Œ!")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()