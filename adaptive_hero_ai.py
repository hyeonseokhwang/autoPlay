"""
ì˜ì›…ì „ì„¤4 ì ì‘í˜• AI í”Œë ˆì´ì–´
ë¡œì»¬ LLM + ê°•í™”í•™ìŠµì„ ê²°í•©í•œ ììœ¨ í•™ìŠµ ì‹œìŠ¤í…œ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from isolated_seeker import IsolatedDOSBoxSeeker
import time
import json
import cv2
import numpy as np
from collections import deque
import requests

class AdaptiveHeroAI:
    """ì ì‘í˜• ì˜ì›…ì „ì„¤4 AI"""
    
    def __init__(self):
        # ê¸°ë³¸ ê²Œì„ ì œì–´
        self.base_seeker = IsolatedDOSBoxSeeker()
        
        # í•™ìŠµ ì‹œìŠ¤í…œ
        self.experience_db = []
        self.success_patterns = {}
        self.failure_patterns = {}
        
        # LLM ì„¤ì • (Ollama ê¸°ë³¸)
        self.llm_endpoint = "http://localhost:11434/api/generate"
        self.llm_model = "llama3.2"  # ë˜ëŠ” "deepseek-coder"
        
        # ê²Œì„ ìƒíƒœ ì¶”ì 
        self.game_memory = deque(maxlen=100)
        self.battle_count = 0
        self.learning_enabled = True
        
        # í–‰ë™ ë§¤í•‘
        self.actions = {
            0: ("move_left", "ì™¼ìª½ ì´ë™"),
            1: ("move_right", "ì˜¤ë¥¸ìª½ ì´ë™"),
            2: ("move_up", "ìœ„ìª½ ì´ë™"), 
            3: ("move_down", "ì•„ë˜ìª½ ì´ë™"),
            4: ("attack", "ê³µê²©/í™•ì¸"),
            5: ("defend", "ë°©ì–´/ì·¨ì†Œ"),
            6: ("wait", "ëŒ€ê¸°"),
        }
        
        print("ğŸ¤– ì ì‘í˜• AI ì´ˆê¸°í™” ì™„ë£Œ!")
        self.check_llm_connection()
    
    def check_llm_connection(self):
        """LLM ì—°ê²° í™•ì¸"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=3)
            if response.status_code == 200:
                models = response.json().get("models", [])
                available_models = [m["name"] for m in models]
                print(f"âœ… LLM ì„œë²„ ì—°ê²°ë¨. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {available_models}")
                
                # ëª¨ë¸ ìë™ ì„ íƒ
                if "deepseek-coder" in available_models:
                    self.llm_model = "deepseek-coder"
                elif "llama3.2" in available_models:
                    self.llm_model = "llama3.2"
                else:
                    self.llm_model = available_models[0] if available_models else "llama3.2"
                
                print(f"ğŸ§  ì„ íƒëœ ëª¨ë¸: {self.llm_model}")
                return True
        except:
            print("âŒ LLM ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ AIë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            print("   Ollama ì„¤ì¹˜ í›„ 'ollama pull llama3.2' ì‹¤í–‰í•˜ì„¸ìš”.")
        
        return False
    
    def analyze_with_llm(self, screen_description, game_context):
        """LLMìœ¼ë¡œ ìƒí™© ë¶„ì„"""
        try:
            prompt = f"""
ë‹¹ì‹ ì€ ì˜ì›…ì „ì„¤4ë¥¼ í”Œë ˆì´í•˜ëŠ” ì „ë¬¸ AIì…ë‹ˆë‹¤.

í˜„ì¬ ìƒí™©:
{screen_description}

ê²Œì„ ì»¨í…ìŠ¤íŠ¸:
- ì „íˆ¬ íšŸìˆ˜: {self.battle_count}
- ìµœê·¼ í–‰ë™: {self.get_recent_actions()}
- í•™ìŠµëœ íŒ¨í„´: {len(self.success_patterns)}ê°œ

ë‹¤ìŒ ì¤‘ ìµœì ì˜ í–‰ë™ì„ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”:
0: ì™¼ìª½ ì´ë™
1: ì˜¤ë¥¸ìª½ ì´ë™  
2: ìœ„ìª½ ì´ë™
3: ì•„ë˜ìª½ ì´ë™
4: ê³µê²©/í™•ì¸
5: ë°©ì–´/ì·¨ì†Œ
6: ëŒ€ê¸°

ìˆ«ìë§Œ ë‹µí•˜ì„¸ìš” (0-6):
"""
            
            response = requests.post(self.llm_endpoint, json={
                "model": self.llm_model,
                "prompt": prompt,
                "stream": False,
                "options": {"temperature": 0.3}
            }, timeout=5)
            
            if response.status_code == 200:
                answer = response.json()["response"].strip()
                
                # ìˆ«ì ì¶”ì¶œ
                for char in answer:
                    if char.isdigit() and int(char) < len(self.actions):
                        action_id = int(char)
                        print(f"ğŸ§  LLM ê²°ì •: {self.actions[action_id][1]} ({action_id})")
                        return action_id
        
        except Exception as e:
            print(f"âš  LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # í´ë°±: íŒ¨í„´ ê¸°ë°˜ ê²°ì •
        return self.pattern_based_decision(game_context)
    
    def pattern_based_decision(self, game_context):
        """í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜ ê²°ì •"""
        
        # ì„±ê³µ íŒ¨í„´ í™œìš©
        context_key = self.get_context_key(game_context)
        
        if context_key in self.success_patterns:
            best_action = max(self.success_patterns[context_key].items(), 
                            key=lambda x: x[1])
            print(f"ğŸ“š íŒ¨í„´ ê¸°ë°˜ ê²°ì •: {self.actions[best_action[0]][1]}")
            return best_action[0]
        
        # ê¸°ë³¸ íƒí—˜ í–‰ë™
        if game_context.get("is_battle", False):
            return 4  # ì „íˆ¬ ì‹œ ê³µê²©
        else:
            return np.random.choice([0, 1])  # í•„ë“œì—ì„œ ì¢Œìš° ì´ë™
    
    def get_context_key(self, game_context):
        """ê²Œì„ ìƒí™©ì„ í‚¤ë¡œ ë³€í™˜"""
        keys = []
        
        if game_context.get("is_battle", False):
            keys.append("battle")
        else:
            keys.append("field")
        
        if game_context.get("enemy_count", 0) > 0:
            keys.append(f"enemies_{game_context['enemy_count']}")
        
        return "_".join(keys)
    
    def get_recent_actions(self):
        """ìµœê·¼ í–‰ë™ ìš”ì•½"""
        if len(self.game_memory) < 3:
            return "ì‹œì‘"
        
        recent = list(self.game_memory)[-3:]
        action_names = [self.actions.get(action, ["unknown"])[0] 
                       for action in recent if isinstance(action, int)]
        return " â†’ ".join(action_names)
    
    def learn_from_result(self, action, game_state_before, game_state_after):
        """ê²°ê³¼ë¡œë¶€í„° í•™ìŠµ"""
        if not self.learning_enabled:
            return
        
        # ì„±ê³µ/ì‹¤íŒ¨ íŒë‹¨
        success = self.evaluate_success(game_state_before, game_state_after, action)
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context_key = self.get_context_key(game_state_before)
        
        # íŒ¨í„´ ì—…ë°ì´íŠ¸
        if success:
            if context_key not in self.success_patterns:
                self.success_patterns[context_key] = {}
            
            if action not in self.success_patterns[context_key]:
                self.success_patterns[context_key][action] = 0
            
            self.success_patterns[context_key][action] += 1
            print(f"âœ… í•™ìŠµ: {context_key} -> {self.actions[action][1]} (ì„±ê³µ)")
        
        else:
            if context_key not in self.failure_patterns:
                self.failure_patterns[context_key] = {}
            
            if action not in self.failure_patterns[context_key]:
                self.failure_patterns[context_key][action] = 0
            
            self.failure_patterns[context_key][action] += 1
            print(f"âŒ í•™ìŠµ: {context_key} -> {self.actions[action][1]} (ì‹¤íŒ¨)")
        
        # ê²½í—˜ ì €ì¥
        experience = {
            "timestamp": time.time(),
            "action": action,
            "state_before": game_state_before,
            "state_after": game_state_after,
            "success": success
        }
        self.experience_db.append(experience)
    
    def evaluate_success(self, state_before, state_after, action):
        """í–‰ë™ì˜ ì„±ê³µ/ì‹¤íŒ¨ í‰ê°€"""
        
        # ì „íˆ¬ ë°œê²¬ì€ ì„±ê³µ
        if not state_before.get("is_battle") and state_after.get("is_battle"):
            return True
        
        # HP ê°ì†ŒëŠ” ì‹¤íŒ¨ (ì „íˆ¬ ì¤‘)
        hp_before = state_before.get("hp", 100)
        hp_after = state_after.get("hp", 100)
        if hp_before > hp_after:
            return False
        
        # ìƒˆë¡œìš´ í™”ë©´ íƒí—˜ì€ ì„±ê³µ
        if self.is_screen_changed(state_before, state_after):
            return True
        
        # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì¤‘ë¦½
        return True
    
    def is_screen_changed(self, state_before, state_after):
        """í™”ë©´ ë³€í™” ê°ì§€"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì´ë¯¸ì§€ ë¹„êµ í•„ìš”
        return np.random.random() > 0.7
    
    def get_screen_description(self, screen):
        """í™”ë©´ì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…"""
        if screen is None:
            return "í™”ë©´ì„ ìº¡ì²˜í•  ìˆ˜ ì—†ìŒ"
        
        # í™”ë©´ ë¶„ì„
        is_battle = self.base_seeker.is_battle_screen(screen)
        
        description = []
        if is_battle:
            description.append("ì „íˆ¬ í™”ë©´ ê°ì§€")
            description.append("HP/MP ë°”ê°€ ë³´ì„")
        else:
            description.append("í•„ë“œ í™”ë©´")
            description.append("ìºë¦­í„°ê°€ ì´ë™ ê°€ëŠ¥í•œ ìƒíƒœ")
        
        # í™”ë©´ ë°ê¸° ë¶„ì„
        gray = cv2.cvtColor(screen, cv2.COLOR_BGR2GRAY)
        brightness = np.mean(gray)
        description.append(f"í™”ë©´ ë°ê¸°: {brightness:.1f}")
        
        return ". ".join(description)
    
    def save_learning_progress(self):
        """í•™ìŠµ ì§„í–‰ìƒí™© ì €ì¥"""
        data = {
            "battle_count": self.battle_count,
            "success_patterns": self.success_patterns,
            "failure_patterns": self.failure_patterns,
            "experience_count": len(self.experience_db)
        }
        
        with open("ai_learning_progress.json", "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ (ê²½í—˜: {len(self.experience_db)}ê°œ)")
    
    def load_learning_progress(self):
        """ì´ì „ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        try:
            with open("ai_learning_progress.json", "r", encoding="utf-8") as f:
                data = json.load(f)
            
            self.battle_count = data.get("battle_count", 0)
            self.success_patterns = data.get("success_patterns", {})
            self.failure_patterns = data.get("failure_patterns", {})
            
            print(f"ğŸ“ ì´ì „ í•™ìŠµ ë°ì´í„° ë¡œë“œ (ì „íˆ¬: {self.battle_count}íšŒ, íŒ¨í„´: {len(self.success_patterns)}ê°œ)")
        
        except FileNotFoundError:
            print("ğŸ“ ìƒˆë¡œìš´ í•™ìŠµ ì‹œì‘")
    
    def adaptive_play(self, max_battles=5):
        """ì ì‘í˜• ìë™ í”Œë ˆì´"""
        
        print(f"ğŸ® ì ì‘í˜• AI í”Œë ˆì´ ì‹œì‘! (ëª©í‘œ: {max_battles}íšŒ ì „íˆ¬)")
        
        # ì´ì „ í•™ìŠµ ë°ì´í„° ë¡œë“œ
        self.load_learning_progress()
        
        if not self.base_seeker.find_dosbox_window():
            print("âŒ DOSBox ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        consecutive_failures = 0
        
        while self.battle_count < max_battles:
            try:
                # í˜„ì¬ í™”ë©´ ë¶„ì„
                screen = self.base_seeker.capture_dosbox_window()
                if screen is None:
                    print("âš  í™”ë©´ ìº¡ì²˜ ì‹¤íŒ¨")
                    consecutive_failures += 1
                    if consecutive_failures > 5:
                        break
                    continue
                
                consecutive_failures = 0
                
                # ê²Œì„ ìƒíƒœ ë¶„ì„
                game_state = {
                    "is_battle": self.base_seeker.is_battle_screen(screen),
                    "screen": screen,
                    "timestamp": time.time()
                }
                
                # ì „íˆ¬ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
                if game_state["is_battle"] and not getattr(self, "_last_battle_state", False):
                    self.battle_count += 1
                    print(f"âš” ì „íˆ¬ #{self.battle_count} ê°ì§€!")
                
                self._last_battle_state = game_state["is_battle"]
                
                # í™”ë©´ ì„¤ëª… ìƒì„±
                screen_description = self.get_screen_description(screen)
                
                # AI ê²°ì • (LLM ìš°ì„ , í´ë°±ì€ íŒ¨í„´ ê¸°ë°˜)
                action = self.analyze_with_llm(screen_description, game_state)
                
                # í–‰ë™ ì‹¤í–‰
                self.execute_action(action)
                
                # ê²°ê³¼ ê´€ì°° ë° í•™ìŠµ
                time.sleep(0.5)  # ë°˜ì‘ ì‹œê°„
                
                new_screen = self.base_seeker.capture_dosbox_window()
                new_game_state = {
                    "is_battle": self.base_seeker.is_battle_screen(new_screen) if new_screen is not None else False,
                    "screen": new_screen,
                    "timestamp": time.time()
                }
                
                # í•™ìŠµ
                self.learn_from_result(action, game_state, new_game_state)
                
                # ë©”ëª¨ë¦¬ì— ì¶”ê°€
                self.game_memory.append(action)
                
                # ì£¼ê¸°ì  ì €ì¥ (5ë²ˆë§ˆë‹¤)
                if len(self.experience_db) % 5 == 0:
                    self.save_learning_progress()
                
                time.sleep(1)  # ë‹¤ìŒ í–‰ë™ê¹Œì§€ ëŒ€ê¸°
                
            except KeyboardInterrupt:
                print("\nâ¹ ì‚¬ìš©ì ì¤‘ë‹¨")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                consecutive_failures += 1
                if consecutive_failures > 3:
                    break
        
        # ìµœì¢… ì €ì¥
        self.save_learning_progress()
        print(f"ğŸ AI í”Œë ˆì´ ì™„ë£Œ! ì´ {self.battle_count}íšŒ ì „íˆ¬")
        self.print_learning_summary()
    
    def execute_action(self, action_id):
        """í–‰ë™ ì‹¤í–‰"""
        action_name = self.actions[action_id][0]
        
        if action_name.startswith("move_"):
            direction = action_name.split("_")[1]
            if direction == "left":
                self.base_seeker.send_key_message(self.base_seeker.VK_LEFT)
            elif direction == "right":
                self.base_seeker.send_key_message(self.base_seeker.VK_RIGHT)
            elif direction == "up":
                self.base_seeker.send_key_message(self.base_seeker.VK_UP)
            elif direction == "down":
                self.base_seeker.send_key_message(self.base_seeker.VK_DOWN)
        
        elif action_name == "attack":
            self.base_seeker.send_key_message(self.base_seeker.VK_RETURN)
        
        elif action_name == "defend":
            self.base_seeker.send_key_message(self.base_seeker.VK_ESCAPE)
        
        # waitì€ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ
        
        print(f"ğŸ¯ ì‹¤í–‰: {self.actions[action_id][1]}")
    
    def print_learning_summary(self):
        """í•™ìŠµ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ“Š í•™ìŠµ ìš”ì•½:")
        print(f"   ì´ ê²½í—˜: {len(self.experience_db)}ê°œ")
        print(f"   ì„±ê³µ íŒ¨í„´: {len(self.success_patterns)}ê°œ")
        print(f"   ì‹¤íŒ¨ íŒ¨í„´: {len(self.failure_patterns)}ê°œ")
        
        if self.success_patterns:
            print("\nğŸ† íš¨ê³¼ì ì¸ íŒ¨í„´:")
            for context, actions in list(self.success_patterns.items())[:3]:
                best_action = max(actions.items(), key=lambda x: x[1])
                action_name = self.actions[best_action[0]][1]
                print(f"   {context}: {action_name} ({best_action[1]}íšŒ ì„±ê³µ)")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš€ ì˜ì›…ì „ì„¤4 ì ì‘í˜• AI ì‹œì‘!")
    print("\ní•„ìš”ì‚¬í•­:")
    print("1. DOSBoxì—ì„œ ì˜ì›…ì „ì„¤4 ì‹¤í–‰")
    print("2. (ì„ íƒ) Ollama LLM ì„œë²„ ì‹¤í–‰")
    print("   - ì„¤ì¹˜: https://ollama.ai/")
    print("   - ëª¨ë¸: ollama pull llama3.2")
    print("\nì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    input()
    
    ai = AdaptiveHeroAI()
    ai.adaptive_play(max_battles=5)

if __name__ == "__main__":
    main()