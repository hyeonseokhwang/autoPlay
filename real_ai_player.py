#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì˜ì›…ì „ì„¤4 ì‹¤ì œ AI ëª¨ë¸ ì—°ê²° ì‹œìŠ¤í…œ
- ì‹¤ì œ Ollama LLM ì—°ê²°
- í™”ë©´ì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…í•´ì„œ ëª¨ë¸ì—ê²Œ ì „ë‹¬
- ëª¨ë¸ì´ ì§ì ‘ ì¶”ë¡ í•˜ê³  í–‰ë™ ê²°ì •
- ì§„ì§œ AIì˜ ì‚¬ê³  ê³¼ì •
"""

import asyncio
import time
import json
import base64
import numpy as np
import cv2
import aiohttp
from datetime import datetime
from collections import deque
from typing import Dict, List, Tuple, Any, Optional
from PIL import ImageGrab, Image
import win32gui
import win32con
import win32api
import io

class RealAIVision:
    """ì‹¤ì œ AIë¥¼ ìœ„í•œ ì‹œê° ì²˜ë¦¬"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.last_screenshot = None
        self.vision_history = deque(maxlen=5)
        
    def describe_screen_for_ai(self, screenshot: np.ndarray) -> str:
        """AIê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í™”ë©´ì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…"""
        if screenshot is None:
            return "í™”ë©´ì„ ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # ê¸°ë³¸ ë¶„ì„
            height, width = screenshot.shape[:2]
            brightness = np.mean(screenshot)
            
            # HSV ë³€í™˜ìœ¼ë¡œ ìƒ‰ìƒ ë¶„ì„
            hsv = cv2.cvtColor(screenshot, cv2.COLOR_RGB2HSV)
            
            # ìƒ‰ìƒ ì˜ì—­ ë¶„ì„
            red_mask1 = cv2.inRange(hsv, (0, 50, 50), (10, 255, 255))
            red_mask2 = cv2.inRange(hsv, (170, 50, 50), (180, 255, 255))
            blue_mask = cv2.inRange(hsv, (100, 50, 50), (130, 255, 255))
            green_mask = cv2.inRange(hsv, (40, 50, 50), (80, 255, 255))
            yellow_mask = cv2.inRange(hsv, (20, 50, 50), (40, 255, 255))
            
            total_pixels = width * height
            red_ratio = (np.sum(red_mask1) + np.sum(red_mask2)) / total_pixels
            blue_ratio = np.sum(blue_mask) / total_pixels
            green_ratio = np.sum(green_mask) / total_pixels
            yellow_ratio = np.sum(yellow_mask) / total_pixels
            
            # ì—£ì§€ ë° í…ìŠ¤ì²˜ ë¶„ì„
            gray = cv2.cvtColor(screenshot, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / total_pixels
            
            # í™”ë©´ì„ 9ê°œ ì˜ì—­ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„
            h_step, w_step = height // 3, width // 3
            region_descriptions = []
            
            region_names = [
                "ì¢Œìƒë‹¨", "ìƒë‹¨ì¤‘ì•™", "ìš°ìƒë‹¨",
                "ì¢Œì¸¡ì¤‘ì•™", "ì •ì¤‘ì•™", "ìš°ì¸¡ì¤‘ì•™", 
                "ì¢Œí•˜ë‹¨", "í•˜ë‹¨ì¤‘ì•™", "ìš°í•˜ë‹¨"
            ]
            
            for i in range(3):
                for j in range(3):
                    y1, y2 = i * h_step, (i + 1) * h_step
                    x1, x2 = j * w_step, (j + 1) * w_step
                    region = screenshot[y1:y2, x1:x2]
                    
                    if region.size > 0:
                        region_brightness = np.mean(region)
                        region_name = region_names[i * 3 + j]
                        
                        if region_brightness > 100:
                            brightness_desc = "ë°ìŒ"
                        elif region_brightness > 50:
                            brightness_desc = "ë³´í†µ"
                        else:
                            brightness_desc = "ì–´ë‘ "
                        
                        region_descriptions.append(f"{region_name}: {brightness_desc}")
            
            # AIë¥¼ ìœ„í•œ ìì—°ì–´ ì„¤ëª… ìƒì„±
            description = f"""
ê²Œì„ í™”ë©´ ë¶„ì„ ê²°ê³¼:

ê¸°ë³¸ ì •ë³´:
- í™”ë©´ í¬ê¸°: {width}x{height}
- ì „ì²´ ë°ê¸°: {brightness:.1f} ({'ë°ìŒ' if brightness > 80 else 'ë³´í†µ' if brightness > 40 else 'ì–´ë‘ '})

ìƒ‰ìƒ ë¶„í¬:
- ë¹¨ê°„ìƒ‰ ì˜ì—­: {red_ratio*100:.1f}% {'(ë§ìŒ)' if red_ratio > 0.05 else '(ì ìŒ)'}
- íŒŒë€ìƒ‰ ì˜ì—­: {blue_ratio*100:.1f}% {'(ë§ìŒ)' if blue_ratio > 0.08 else '(ì ìŒ)'}  
- ë…¹ìƒ‰ ì˜ì—­: {green_ratio*100:.1f}% {'(ë§ìŒ)' if green_ratio > 0.1 else '(ì ìŒ)'}
- ë…¸ë€ìƒ‰ ì˜ì—­: {yellow_ratio*100:.1f}% {'(ë§ìŒ)' if yellow_ratio > 0.03 else '(ì ìŒ)'}

í™”ë©´ íŠ¹ì„±:
- ì—£ì§€ ë°€ë„: {edge_density*100:.1f}% {'(ë³µì¡í•¨)' if edge_density > 0.1 else '(ë‹¨ìˆœí•¨)'}
- ì „ë°˜ì  íŠ¹ì„±: {'UI/ë©”ë‰´ í™”ë©´' if blue_ratio > 0.1 or yellow_ratio > 0.05 else 'ê²Œì„ í•„ë“œ' if green_ratio > 0.05 else 'ë¶ˆëª…í™•í•œ í™”ë©´'}

í™”ë©´ ì˜ì—­ë³„ ìƒíƒœ:
{chr(10).join(region_descriptions)}

ì´ì „ í™”ë©´ê³¼ì˜ ì°¨ì´:
{self._describe_screen_changes()}
"""
            
            self.vision_history.append({
                'timestamp': datetime.now(),
                'description': description,
                'stats': {
                    'brightness': brightness,
                    'red_ratio': red_ratio,
                    'blue_ratio': blue_ratio,
                    'green_ratio': green_ratio,
                    'yellow_ratio': yellow_ratio,
                    'edge_density': edge_density
                }
            })
            
            return description
            
        except Exception as e:
            return f"í™”ë©´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
    
    def _describe_screen_changes(self) -> str:
        """ì´ì „ í™”ë©´ê³¼ì˜ ë³€í™” ì„¤ëª…"""
        if len(self.vision_history) < 2:
            return "ì²« ë²ˆì§¸ ê´€ì°°ì…ë‹ˆë‹¤."
        
        prev_stats = self.vision_history[-2]['stats']
        
        changes = []
        if len(self.vision_history) >= 2:
            current_stats = {
                'brightness': np.mean(self.last_screenshot) if self.last_screenshot is not None else 0,
                'red_ratio': 0, 'blue_ratio': 0, 'green_ratio': 0, 'yellow_ratio': 0
            }
            
            brightness_change = abs(current_stats['brightness'] - prev_stats['brightness'])
            if brightness_change > 20:
                changes.append(f"ë°ê¸° {'ì¦ê°€' if current_stats['brightness'] > prev_stats['brightness'] else 'ê°ì†Œ'}")
            
            for color in ['red_ratio', 'blue_ratio', 'green_ratio']:
                if abs(current_stats.get(color, 0) - prev_stats.get(color, 0)) > 0.03:
                    changes.append(f"{color.split('_')[0]} ìƒ‰ìƒ ë³€í™” ê°ì§€")
        
        return "ë³€í™”: " + ", ".join(changes) if changes else "í° ë³€í™” ì—†ìŒ"

class RealAIBrain:
    """ì‹¤ì œ AI ëª¨ë¸ ì—°ê²° ë° ì¶”ë¡ """
    
    def __init__(self, model_name: str = "qwen2.5-coder:7b"):
        """ì´ˆê¸°í™”"""
        self.model_name = model_name
        self.ollama_url = "http://localhost:11434"
        self.conversation_history = deque(maxlen=20)
        self.total_thoughts = 0
        
    async def think_and_decide(self, screen_description: str, 
                              action_history: List[str], 
                              battle_count: int,
                              step_count: int) -> Dict[str, Any]:
        """AIê°€ ì§ì ‘ ìƒê°í•˜ê³  í–‰ë™ ê²°ì •"""
        
        self.total_thoughts += 1
        
        # AIì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ì˜ì›…ì „ì„¤4 RPG í”Œë ˆì´ AI. ë¹ ë¥¸ ê²°ì • í•„ìš”.

í™”ë©´: {screen_description[:300]}

ìŠ¤í…: {step_count} | ì „íˆ¬: {battle_count} | ìµœê·¼: {action_history[-3:] if action_history else 'ì—†ìŒ'}

í–‰ë™: left/right/up/down/space/enter/z/x/a/s/1/2

ëª©í‘œ: íƒí—˜, ì „íˆ¬ ì°¾ê¸°, ìƒí˜¸ì‘ìš©

ë¹ ë¥´ê²Œ JSONìœ¼ë¡œ ë‹µë³€:
{{
    "thoughts": "ì§§ì€ ë¶„ì„",
    "action": "í–‰ë™ì„ íƒ",
    "reason": "ì´ìœ ",
    "confidence": 0.8
}}
"""
        
        try:
            # Ollama API í˜¸ì¶œ
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,  # ë” ë¹ ë¥¸ ê²°ì •
                        "top_p": 0.7,       # ë” ì§‘ì¤‘ëœ ì„ íƒ
                        "max_tokens": 200,   # ë” ì§§ì€ ì‘ë‹µ
                        "num_ctx": 1024,     # ë” ì‘ì€ ì»¨í…ìŠ¤íŠ¸
                        "num_predict": 150   # ë” ì ì€ ì˜ˆì¸¡
                    }
                }
                
                print(f"ğŸ§  AI ì‚¬ê³  ì¤‘... ({self.total_thoughts}ë²ˆì§¸ ìƒê°)")
                
                async with session.post(f"{self.ollama_url}/api/generate", 
                                      json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        ai_response = result.get('response', '')
                        
                        # JSON íŒŒì‹± ì‹œë„
                        try:
                            # JSON ë¶€ë¶„ ì¶”ì¶œ
                            json_start = ai_response.find('{')
                            json_end = ai_response.rfind('}') + 1
                            
                            if json_start >= 0 and json_end > json_start:
                                json_str = ai_response[json_start:json_end]
                                ai_decision = json.loads(json_str)
                                
                                # ëŒ€í™” ê¸°ë¡ ì €ì¥
                                self.conversation_history.append({
                                    'step': step_count,
                                    'screen': screen_description[:200] + "...",
                                    'ai_response': ai_decision,
                                    'timestamp': datetime.now()
                                })
                                
                                return ai_decision
                            
                        except json.JSONDecodeError as e:
                            print(f"âš ï¸ AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                            print(f"ì›ë³¸ ì‘ë‹µ: {ai_response[:500]}...")
                    
                    else:
                        print(f"âŒ Ollama API ì˜¤ë¥˜: {response.status}")
                        
        except Exception as e:
            print(f"âŒ AI ì—°ê²° ì‹¤íŒ¨: {e}")
        
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        return {
            "thoughts": "AI ì—°ê²°ì— ë¬¸ì œê°€ ìˆì–´ ê¸°ë³¸ íƒí—˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.",
            "reasoning": "ì•ˆì „í•œ íƒí—˜ í–‰ë™ì„ ì„ íƒí•©ë‹ˆë‹¤.",
            "action": "right",
            "reason": "ìš°ì¸¡ íƒí—˜ìœ¼ë¡œ ìƒˆë¡œìš´ ì˜ì—­ì„ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.",
            "expectation": "ìƒˆë¡œìš´ í™”ë©´ì´ë‚˜ ìƒí˜¸ì‘ìš©ì„ ë°œê²¬í•˜ê¸°ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.",
            "curiosity_level": 0.7,
            "confidence": 0.5
        }
    
    def get_learning_summary(self) -> str:
        """AIì˜ í•™ìŠµ ìš”ì•½"""
        if not self.conversation_history:
            return "ì•„ì§ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        actions_taken = [conv['ai_response'].get('action', '') for conv in self.conversation_history]
        action_counts = {}
        for action in actions_taken:
            action_counts[action] = action_counts.get(action, 0) + 1
        
        most_used_action = max(action_counts, key=action_counts.get) if action_counts else "ì—†ìŒ"
        
        return f"""
AI í•™ìŠµ ìš”ì•½:
- ì´ ì‚¬ê³  íšŸìˆ˜: {self.total_thoughts}
- ê¸°ë¡ëœ ëŒ€í™”: {len(self.conversation_history)}
- ê°€ì¥ ì„ í˜¸í•˜ëŠ” í–‰ë™: {most_used_action}
- í–‰ë™ ë¶„í¬: {action_counts}
"""

class RealAIGameController:
    """ì‹¤ì œ AIìš© ê²Œì„ ì»¨íŠ¸ë¡¤ëŸ¬"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.dosbox_window = None
        self.game_region = None
        
    def find_game_window(self) -> bool:
        """ê²Œì„ ì°½ ì°¾ê¸°"""
        def enum_callback(hwnd, windows):
            if win32gui.IsWindowVisible(hwnd):
                window_text = win32gui.GetWindowText(hwnd)
                if 'dosbox' in window_text.lower() or 'ED4' in window_text:
                    windows.append(hwnd)
            return True

        windows = []
        win32gui.EnumWindows(enum_callback, windows)
        
        if windows:
            self.dosbox_window = windows[0]
            self.game_region = win32gui.GetWindowRect(self.dosbox_window)
            print(f"ğŸ® ì‹¤ì œ ê²Œì„ ì—°ê²°: {self.game_region}")
            return True
        
        return False
    
    def capture_screen(self) -> np.ndarray:
        """í™”ë©´ ìº¡ì²˜"""
        try:
            screenshot = ImageGrab.grab(self.game_region)
            return np.array(screenshot)
        except Exception as e:
            print(f"âŒ í™”ë©´ ìº¡ì²˜ ì‹¤íŒ¨: {e}")
            return None
    
    def execute_ai_action(self, action: str) -> bool:
        """AIì˜ ê²°ì •ì„ ê²Œì„ì— ì „ì†¡"""
        if not self.dosbox_window:
            return False
        
        try:
            win32gui.SetForegroundWindow(self.dosbox_window)
            time.sleep(0.02)  # ìµœì†Œ ì§€ì—°
            
            key_map = {
                'left': 0x25, 'right': 0x27, 'up': 0x26, 'down': 0x28,
                'space': 0x20, 'enter': 0x0D, 'z': 0x5A, 'x': 0x58,
                'a': 0x41, 's': 0x53, '1': 0x31, '2': 0x32
            }
            
            if action in key_map:
                vk_code = key_map[action]
                win32api.keybd_event(vk_code, 0, 0, 0)
                time.sleep(0.03)  # ìµœê³ ì† í‚¤ì…ë ¥
                win32api.keybd_event(vk_code, 0, win32con.KEYEVENTF_KEYUP, 0)
                return True
                
        except Exception as e:
            print(f"âŒ í–‰ë™ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        return False

class RealAIPlayer:
    """ì‹¤ì œ AI í”Œë ˆì´ì–´ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.vision = RealAIVision()
        self.brain = RealAIBrain()
        self.controller = RealAIGameController()
        
        # ê²Œì„ ìƒíƒœ ì¶”ì 
        self.step_count = 0
        self.battle_count = 0
        self.action_history = deque(maxlen=50)
        self.session_start = time.time()
        
        print("ğŸ¤– ì‹¤ì œ AI í”Œë ˆì´ì–´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print("ğŸ§  AI ëª¨ë¸: Ollama LLM ì—°ê²°")
        print("ğŸ‘ï¸ ë¹„ì „: ì‹¤ì‹œê°„ í™”ë©´ ë¶„ì„ ë° ìì—°ì–´ ë³€í™˜")
        print("ğŸ® ì»¨íŠ¸ë¡¤ëŸ¬: ì§ì ‘ ê²Œì„ ì¡°ì‘")
        
    async def ai_gaming_step(self) -> bool:
        """AIì˜ í•œ ë²ˆ ê²Œì„ ìŠ¤í…"""
        self.step_count += 1
        
        # 1. í™”ë©´ ê´€ì°°
        screenshot = self.controller.capture_screen()
        if screenshot is None:
            print("âŒ í™”ë©´ì„ ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # 2. AIê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í™”ë©´ ì„¤ëª…
        screen_description = self.vision.describe_screen_for_ai(screenshot)
        
        # 3. AIê°€ ì§ì ‘ ìƒê°í•˜ê³  ê²°ì •
        ai_decision = await self.brain.think_and_decide(
            screen_description, 
            list(self.action_history),
            self.battle_count,
            self.step_count
        )
        
        # 4. ê°„ë‹¨í•œ ì¶œë ¥ (ì†ë„ ìµœì í™”)
        if self.step_count % 5 == 0:  # 5ë²ˆì— í•œë²ˆë§Œ ì¶œë ¥
            print(f"ï¿½ #{self.step_count}: {ai_decision.get('action')} | {ai_decision.get('thoughts', '...')[:50]}...")
        
        # 5. í–‰ë™ ì‹¤í–‰
        action = ai_decision.get('action', 'right')
        success = self.controller.execute_ai_action(action)
        
        if success:
            self.action_history.append(action)
            print(f"   âœ… ì‹¤í–‰ë¨: {action.upper()}")
            
            # ìµœì†Œ ëŒ€ê¸°
            await asyncio.sleep(0.02)
            
            # ê°„ë‹¨í•œ ì „íˆ¬ ê°ì§€ (í™”ë©´ ë³€í™” ê¸°ë°˜)
            if self._detect_battle_from_ai_perspective(ai_decision):
                self.battle_count += 1
                print(f"   âš”ï¸ AIê°€ ì „íˆ¬ ìƒí™© ê°ì§€! ì´ {self.battle_count}íšŒ")
            
            return True
        else:
            print(f"   âŒ í–‰ë™ ì‹¤í–‰ ì‹¤íŒ¨")
            return False
    
    def _detect_battle_from_ai_perspective(self, ai_decision: Dict) -> bool:
        """AI ê´€ì ì—ì„œ ì „íˆ¬ ê°ì§€"""
        # AIì˜ ìƒê°ì´ë‚˜ ì¶”ë¡ ì— ì „íˆ¬ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        thoughts = ai_decision.get('thoughts', '').lower()
        reasoning = ai_decision.get('reasoning', '').lower()
        
        battle_keywords = ['ì „íˆ¬', 'battle', 'ì ', 'enemy', 'ì‹¸ì›€', 'fight', 'ê³µê²©', 'attack', 'ëª¬ìŠ¤í„°', 'monster']
        
        for keyword in battle_keywords:
            if keyword in thoughts or keyword in reasoning:
                return True
        
        # í˜¸ê¸°ì‹¬ì´ë‚˜ í™•ì‹ ë„ê°€ ë†’ì„ ë•Œë„ íŠ¹ë³„í•œ ìƒí™©ìœ¼ë¡œ ê°„ì£¼
        curiosity = ai_decision.get('curiosity_level', 0)
        confidence = ai_decision.get('confidence', 0)
        
        if curiosity > 0.8 and confidence > 0.7:
            return True
        
        return False
    
    async def run_real_ai_session(self, max_steps: int = 999999, target_battles: int = 999999) -> None:
        """ì‹¤ì œ AI ì„¸ì…˜ ì‹¤í–‰"""
        print(f"\nğŸš€ ìµœê³ ì†ë„ AI í”Œë ˆì´ ì„¸ì…˜ ì‹œì‘!")
        print(f"âš¡ ë¬´ì œí•œ ëª¨ë“œ: íšŸìˆ˜ ì œí•œ ì—†ìŒ")
        print(f"ğŸ¤– AIê°€ ìµœê³  ì†ë„ë¡œ ìƒê°í•˜ê³  íŒë‹¨í•©ë‹ˆë‹¤!\n")
        
        if not self.controller.find_game_window():
            print("âŒ ê²Œì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        successful_steps = 0
        
        while (self.step_count < max_steps and 
               self.battle_count < target_battles):
            
            step_success = await self.ai_gaming_step()
            if step_success:
                successful_steps += 1
            
            await asyncio.sleep(0.05)  # ìµœê³  ì†ë„
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥ (ë” ìì£¼)
            if self.step_count % 25 == 0:
                elapsed = time.time() - self.session_start
                print(f"\nğŸ“Š ì§„í–‰ ìƒí™© (ìŠ¤í… {self.step_count}):")
                print(f"   â±ï¸ ê²½ê³¼ ì‹œê°„: {elapsed:.1f}ì´ˆ")
                print(f"   âš”ï¸ ì „íˆ¬ ë°œê²¬: {self.battle_count}/{target_battles}")
                print(f"   âœ… ì„±ê³µí•œ í–‰ë™: {successful_steps}/{self.step_count}")
                print(f"   ğŸ® ìµœê·¼ í–‰ë™: {list(self.action_history)[-5:]}")
        
        # ìµœì¢… ê²°ê³¼
        elapsed = time.time() - self.session_start
        success_rate = successful_steps / max(self.step_count, 1)
        
        print(f"\nğŸ ì‹¤ì œ AI ì„¸ì…˜ ì™„ë£Œ!")
        print(f"â±ï¸ ì´ ì‹œê°„: {elapsed:.1f}ì´ˆ")
        print(f"ğŸ® ì´ ìŠ¤í…: {self.step_count}")
        print(f"âš”ï¸ ì „íˆ¬ ë°œê²¬: {self.battle_count}/{target_battles}")
        print(f"ğŸ“ˆ í–‰ë™ ì„±ê³µë¥ : {success_rate:.1%}")
        
        # AI í•™ìŠµ ìš”ì•½
        print(f"\nğŸ“š AI í•™ìŠµ ìš”ì•½:")
        print(self.brain.get_learning_summary())
        
        if self.battle_count >= target_battles:
            print("\nğŸ‰ ëª©í‘œ ë‹¬ì„±! ì‹¤ì œ AIê°€ ì„±ê³µì ìœ¼ë¡œ ê²Œì„ì„ í”Œë ˆì´í–ˆìŠµë‹ˆë‹¤!")
        else:
            print("\nğŸ“ˆ AIê°€ ì‹¤ì œ ê²Œì„ ê²½í—˜ì„ ìŒ“ì•˜ìŠµë‹ˆë‹¤!")

# ì‹¤í–‰
if __name__ == "__main__":
    async def main():
        player = RealAIPlayer()
        await player.run_real_ai_session()  # ë¬´ì œí•œ ëª¨ë“œ
    
    print("ğŸ¤– ì‹¤ì œ AI ëª¨ë¸ ì—°ê²° ê²Œì„ í”Œë ˆì´ì–´")
    print("=" * 70)
    print("ğŸ§  íŠ¹ì§•: ì§„ì§œ LLM ì¶”ë¡  + ì‹¤ì‹œê°„ í™”ë©´ ë¶„ì„ + ìì—°ì–´ ì‚¬ê³ ")
    asyncio.run(main())